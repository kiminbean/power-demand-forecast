Using device: mps

============================================================
제주시 전력 수요 예측 - RNN 계열 모델
논문: 기상 변수 통합 순환 신경망을 활용한 제주시 전력 수요 예측
목표: R² 75% 달성
============================================================
============================================================
데이터 로드 및 전처리 시작...
============================================================
전력 데이터: 4383행, 2013-01-01 00:00:00 ~ 2024-12-31 00:00:00
기온 데이터: 4717행, 2013-01-01 00:00:00 ~ 2025-11-30 00:00:00
일사량 데이터: 4715행
이슬점 온도 데이터: 4717행
관광객 데이터: 4718행
전기차 데이터: 4353행

병합 후 데이터: 4387행, 10열
결측치 현황:
date              0
power_mwh         0
avg_temp          0
min_temp          0
max_temp          0
sunlight          2
dew_point         0
visitors          9
ev_cumulative    30
ev_daily_new     30
dtype: int64

============================================================
이상치 탐지 및 처리 (IQR 기반 Capping)
============================================================
컬럼              하한 이상치       상한 이상치       총계       하한값          상한값         
---------------------------------------------------------------------------
power_mwh       0            1            1        3054.87      16062.59    
visitors        123          7            130      17771.25     56537.25    

총 131개 이상치를 Capping 처리했습니다.

최종 데이터: 4022행, 62열
기간: 2014-01-01 00:00:00 ~ 2024-12-31 00:00:00

============================================================
피어슨 상관계수 분석
============================================================

전력 수요와 변수 간 상관계수 (상위 20개):
--------------------------------------------------
power_rolling_mean_3               : +0.9599  ★★★
power_rolling_max_3                : +0.9502  ★★★
power_rolling_min_3                : +0.9447  ★★★
power_rolling_mean_7               : +0.9260  ★★★
power_lag_1                        : +0.9215  ★★★
power_rolling_max_7                : +0.9097  ★★★
power_rolling_min_7                : +0.9047  ★★★
power_rolling_mean_14              : +0.8966  ★★★
power_rolling_max_14               : +0.8770  ★★★
power_rolling_mean_21              : +0.8756  ★★★
power_rolling_min_14               : +0.8696  ★★★
power_lag_2                        : +0.8624  ★★★
power_rolling_mean_30              : +0.8532  ★★★
power_rolling_max_21               : +0.8521  ★★★
power_rolling_min_21               : +0.8469  ★★★
power_lag_3                        : +0.8412  ★★★
power_rolling_max_30               : +0.8303  ★★★
power_rolling_min_30               : +0.8241  ★★★
power_lag_7                        : +0.8139  ★★★
power_lag_14                       : +0.7644  ★★★
상관관계 히트맵이 '/Users/ibkim/Ormi_1/power-demand-forecast/results/correlation_heatmap.png'에 저장되었습니다.

고상관 피처 (r >= 0.7): 24개

사용할 피처 (20개):
   1. power_rolling_mean_3           (r=+0.960)
   2. power_rolling_max_3            (r=+0.950)
   3. power_rolling_min_3            (r=+0.945)
   4. power_rolling_mean_7           (r=+0.926)
   5. power_lag_1                    (r=+0.921)
   6. power_rolling_max_7            (r=+0.910)
   7. power_rolling_min_7            (r=+0.905)
   8. power_rolling_mean_14          (r=+0.897)
   9. power_rolling_max_14           (r=+0.877)
  10. power_rolling_min_14           (r=+0.870)
  11. power_lag_2                    (r=+0.862)
  12. power_lag_3                    (r=+0.841)
  13. power_lag_7                    (r=+0.814)
  14. year                           (r=+0.732)
  15. power_lag_365                  (r=+0.696)
  16. CDD                            (r=+0.289)
  17. HDD                            (r=+0.268)
  18. month_sin                      (r=+0.085)
  19. month_cos                      (r=+0.107)
  20. is_weekend                     (r=-0.112)

============================================================
자동 하이퍼파라미터 튜닝 시작 (목표 R²: 0.75)
============================================================

데이터 분할:
  Train: 3291 샘플 (~2022-12-31)
  Val:   365 샘플
  Test:  366 샘플
  피처 수: 20

============================================================
Iteration 1/14 (Seed: 42)
Config: hidden=96, layers=1, seq=7, batch=32, lr=0.0005
============================================================

  Training BiLSTM...
    BiLSTM: MAE=713.77, RMSE=912.36, R²=0.7258 (72.58%)
    ★ New Best R²: 0.7258 (72.58%)

============================================================
Iteration 2/14 (Seed: 1111)
Config: hidden=96, layers=1, seq=7, batch=32, lr=0.0005
============================================================

  Training BiLSTM...
    BiLSTM: MAE=715.98, RMSE=915.83, R²=0.7237 (72.37%)

============================================================
Iteration 3/14 (Seed: 2222)
Config: hidden=96, layers=1, seq=7, batch=32, lr=0.0005
============================================================

  Training BiLSTM...
    BiLSTM: MAE=715.81, RMSE=912.66, R²=0.7256 (72.56%)

============================================================
Iteration 4/14 (Seed: 3333)
Config: hidden=96, layers=1, seq=7, batch=32, lr=0.0005
============================================================

  Training BiLSTM...
    BiLSTM: MAE=721.74, RMSE=919.77, R²=0.7213 (72.13%)

============================================================
Iteration 5/14 (Seed: 42)
Config: hidden=96, layers=1, seq=7, batch=32, lr=0.0003
============================================================

  Training BiLSTM...
    BiLSTM: MAE=720.02, RMSE=921.51, R²=0.7202 (72.02%)

============================================================
Iteration 6/14 (Seed: 1111)
Config: hidden=96, layers=1, seq=7, batch=32, lr=0.0003
============================================================

  Training BiLSTM...
    BiLSTM: MAE=723.40, RMSE=922.27, R²=0.7198 (71.98%)

============================================================
Iteration 7/14 (Seed: 42)
Config: hidden=112, layers=1, seq=7, batch=32, lr=0.0005
============================================================

  Training BiLSTM...
    BiLSTM: MAE=722.11, RMSE=923.66, R²=0.7189 (71.89%)

============================================================
Iteration 8/14 (Seed: 1111)
Config: hidden=112, layers=1, seq=7, batch=32, lr=0.0005
============================================================

  Training BiLSTM...
    BiLSTM: MAE=714.43, RMSE=913.41, R²=0.7251 (72.51%)

============================================================
Iteration 9/14 (Seed: 42)
Config: hidden=80, layers=1, seq=7, batch=32, lr=0.0005
============================================================

  Training BiLSTM...
    BiLSTM: MAE=756.90, RMSE=958.05, R²=0.6976 (69.76%)

============================================================
Iteration 10/14 (Seed: 1111)
Config: hidden=80, layers=1, seq=7, batch=32, lr=0.0005
============================================================

  Training BiLSTM...
    BiLSTM: MAE=743.26, RMSE=945.98, R²=0.7052 (70.52%)

============================================================
Iteration 11/14 (Seed: 42)
Config: hidden=96, layers=1, seq=7, batch=32, lr=0.0007
============================================================

  Training BiLSTM...
    BiLSTM: MAE=717.14, RMSE=913.53, R²=0.7251 (72.51%)

============================================================
Iteration 12/14 (Seed: 1111)
Config: hidden=96, layers=1, seq=7, batch=32, lr=0.0007
============================================================

  Training BiLSTM...
    BiLSTM: MAE=717.50, RMSE=918.09, R²=0.7223 (72.23%)

============================================================
Iteration 13/14 (Seed: 4444)
Config: hidden=96, layers=1, seq=7, batch=32, lr=0.001
============================================================

  Training BiLSTM...
    BiLSTM: MAE=718.93, RMSE=916.49, R²=0.7233 (72.33%)

============================================================
Iteration 14/14 (Seed: 5555)
Config: hidden=96, layers=1, seq=7, batch=32, lr=0.001
============================================================

  Training BiLSTM...
    BiLSTM: MAE=742.39, RMSE=930.46, R²=0.7148 (71.48%)

============================================================
최종 Best R²: 0.7258 (72.58%) - BiLSTM
============================================================

============================================================
앙상블 성능 계산 (14개 모델)
============================================================
  [단순평균] MAE=716.84, RMSE=915.25, R²=0.7240 (72.40%)
    모델 1: R²=0.7258, 가중치=0.072
    모델 2: R²=0.7237, 가중치=0.072
    모델 3: R²=0.7256, 가중치=0.072
    모델 4: R²=0.7213, 가중치=0.072
    모델 5: R²=0.7202, 가중치=0.072
    모델 6: R²=0.7198, 가중치=0.071
    모델 7: R²=0.7189, 가중치=0.071
    모델 8: R²=0.7251, 가중치=0.072
    모델 9: R²=0.6976, 가중치=0.069
    모델 10: R²=0.7052, 가중치=0.070
    모델 11: R²=0.7251, 가중치=0.072
    모델 12: R²=0.7223, 가중치=0.072
    모델 13: R²=0.7233, 가중치=0.072
    모델 14: R²=0.7148, 가중치=0.071
  [가중평균] MAE=716.81, RMSE=915.18, R²=0.7241 (72.41%)

  ▶ 최적 앙상블: 가중평균 R²=0.7241 (72.41%)

목표 R² 미달성 - 하이브리드 앙상블 시도...

============================================================
V10: 하이브리드 앙상블 (BiLSTM + Gradient Boosting)
============================================================
Train: 3291, Val: 365, Test: 366

[1] BiLSTM 학습...
  BiLSTM R²: 0.7092 (70.92%)

[2] Gradient Boosting으로 잔차 학습...
  LightGBM 잔차 학습...
  BiLSTM + LightGBM R²: 0.7042 (70.42%)

최종 결과: BiLSTM R²=0.7092 (70.92%)

============================================================
최종 결과
============================================================

최적 모델: BiLSTM

하이퍼파라미터:
  hidden_dim: 96
  num_layers: 1
  seq_length: 7
  batch_size: 32
  lr: 0.0005
  dropout: 0.1
  epochs: 1500
  seed: 42
  model: BiLSTM

성능 지표:
  MAE:  713.77 MWh
  MSE:  832396.12
  RMSE: 912.36 MWh
  R²:   0.7258 (72.58%)
  MAPE: 6.18%

============================================================
결과 그래프가 '/Users/ibkim/Ormi_1/power-demand-forecast/results/results.png'에 저장되었습니다.

모델이 '/Users/ibkim/Ormi_1/power-demand-forecast/best_model.pt'에 저장되었습니다.
