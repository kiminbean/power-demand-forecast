Using device: mps

============================================================
제주시 전력 수요 예측 - RNN 계열 모델
논문: 기상 변수 통합 순환 신경망을 활용한 제주시 전력 수요 예측
목표: R² 75% 달성
============================================================
============================================================
데이터 로드 및 전처리 시작...
============================================================
전력 데이터: 4383행, 2013-01-01 00:00:00 ~ 2024-12-31 00:00:00
기온 데이터: 4717행, 2013-01-01 00:00:00 ~ 2025-11-30 00:00:00
일사량 데이터: 4715행
이슬점 온도 데이터: 4717행
관광객 데이터: 4718행
전기차 데이터: 4353행

병합 후 데이터: 4387행, 10열
결측치 현황:
date              0
power_mwh         0
avg_temp          0
min_temp          0
max_temp          0
sunlight          2
dew_point         0
visitors          9
ev_cumulative    30
ev_daily_new     30
dtype: int64

============================================================
이상치 탐지 및 처리 (IQR 기반 Capping)
============================================================
컬럼              하한 이상치       상한 이상치       총계       하한값          상한값         
---------------------------------------------------------------------------
power_mwh       0            1            1        3054.87      16062.59    
visitors        123          7            130      17771.25     56537.25    

총 131개 이상치를 Capping 처리했습니다.

최종 데이터: 4022행, 62열
기간: 2014-01-01 00:00:00 ~ 2024-12-31 00:00:00

============================================================
피어슨 상관계수 분석
============================================================

전력 수요와 변수 간 상관계수 (상위 20개):
--------------------------------------------------
power_rolling_mean_3               : +0.9599  ★★★
power_rolling_max_3                : +0.9502  ★★★
power_rolling_min_3                : +0.9447  ★★★
power_rolling_mean_7               : +0.9260  ★★★
power_lag_1                        : +0.9215  ★★★
power_rolling_max_7                : +0.9097  ★★★
power_rolling_min_7                : +0.9047  ★★★
power_rolling_mean_14              : +0.8966  ★★★
power_rolling_max_14               : +0.8770  ★★★
power_rolling_mean_21              : +0.8756  ★★★
power_rolling_min_14               : +0.8696  ★★★
power_lag_2                        : +0.8624  ★★★
power_rolling_mean_30              : +0.8532  ★★★
power_rolling_max_21               : +0.8521  ★★★
power_rolling_min_21               : +0.8469  ★★★
power_lag_3                        : +0.8412  ★★★
power_rolling_max_30               : +0.8303  ★★★
power_rolling_min_30               : +0.8241  ★★★
power_lag_7                        : +0.8139  ★★★
power_lag_14                       : +0.7644  ★★★
상관관계 히트맵이 '/Users/ibkim/Ormi_1/power-demand-forecast/results/correlation_heatmap.png'에 저장되었습니다.

고상관 피처 (r >= 0.7): 24개

사용할 피처 (26개):
   1. power_rolling_mean_3           (r=+0.960)
   2. power_rolling_max_3            (r=+0.950)
   3. power_rolling_min_3            (r=+0.945)
   4. power_rolling_mean_7           (r=+0.926)
   5. power_lag_1                    (r=+0.921)
   6. power_rolling_max_7            (r=+0.910)
   7. power_rolling_min_7            (r=+0.905)
   8. power_rolling_mean_14          (r=+0.897)
   9. power_rolling_max_14           (r=+0.877)
  10. power_rolling_min_14           (r=+0.870)
  11. power_lag_2                    (r=+0.862)
  12. power_lag_3                    (r=+0.841)
  13. power_rolling_max_30           (r=+0.830)
  14. power_rolling_min_30           (r=+0.824)
  15. power_lag_7                    (r=+0.814)
  16. power_rolling_mean_21          (r=+0.876)
  17. power_rolling_max_21           (r=+0.852)
  18. power_rolling_min_21           (r=+0.847)
  19. year                           (r=+0.732)
  20. power_lag_365                  (r=+0.696)
  21. power_lag_14                   (r=+0.764)
  22. CDD                            (r=+0.289)
  23. HDD                            (r=+0.268)
  24. month_sin                      (r=+0.085)
  25. month_cos                      (r=+0.107)
  26. is_weekend                     (r=-0.112)

============================================================
자동 하이퍼파라미터 튜닝 시작 (목표 R²: 0.75)
============================================================

데이터 분할:
  Train: 3291 샘플 (~2022-12-31)
  Val:   365 샘플
  Test:  366 샘플
  피처 수: 26

============================================================
Iteration 1/15 (Seed: 5678)
Config: hidden=64, layers=1, seq=7, batch=32, lr=0.002
============================================================

  Training BiLSTM...
    BiLSTM: MAE=742.25, RMSE=939.74, R²=0.7091 (70.91%)
    ★ New Best R²: 0.7091 (70.91%)

============================================================
Iteration 2/15 (Seed: 5678)
Config: hidden=64, layers=1, seq=7, batch=32, lr=0.001
============================================================

  Training BiLSTM...
    BiLSTM: MAE=747.55, RMSE=949.37, R²=0.7031 (70.31%)

============================================================
Iteration 3/15 (Seed: 5678)
Config: hidden=128, layers=1, seq=7, batch=32, lr=0.001
============================================================

  Training BiLSTM...
    BiLSTM: MAE=721.66, RMSE=928.18, R²=0.7162 (71.62%)
    ★ New Best R²: 0.7162 (71.62%)

============================================================
Iteration 4/15 (Seed: 5678)
Config: hidden=128, layers=1, seq=7, batch=32, lr=0.0015
============================================================

  Training BiLSTM...
    BiLSTM: MAE=730.53, RMSE=926.66, R²=0.7171 (71.71%)
    ★ New Best R²: 0.7171 (71.71%)

============================================================
Iteration 5/15 (Seed: 5678)
Config: hidden=64, layers=1, seq=7, batch=16, lr=0.001
============================================================

  Training BiLSTM...
    BiLSTM: MAE=740.05, RMSE=933.70, R²=0.7128 (71.28%)

============================================================
Iteration 6/15 (Seed: 5678)
Config: hidden=64, layers=1, seq=7, batch=64, lr=0.002
============================================================

  Training BiLSTM...
    BiLSTM: MAE=733.36, RMSE=932.33, R²=0.7136 (71.36%)

============================================================
Iteration 7/15 (Seed: 5678)
Config: hidden=64, layers=2, seq=7, batch=32, lr=0.001
============================================================

  Training BiLSTM...
    BiLSTM: MAE=859.54, RMSE=1096.36, R²=0.6040 (60.40%)

============================================================
Iteration 8/15 (Seed: 5678)
Config: hidden=96, layers=2, seq=7, batch=32, lr=0.001
============================================================

  Training BiLSTM...
    BiLSTM: MAE=903.41, RMSE=1130.70, R²=0.5788 (57.88%)

============================================================
Iteration 9/15 (Seed: 5678)
Config: hidden=64, layers=1, seq=14, batch=32, lr=0.001
============================================================

  Training BiLSTM...
    BiLSTM: MAE=734.04, RMSE=929.41, R²=0.7184 (71.84%)
    ★ New Best R²: 0.7184 (71.84%)

============================================================
Iteration 10/15 (Seed: 5678)
Config: hidden=64, layers=1, seq=5, batch=32, lr=0.002
============================================================

  Training BiLSTM...
    BiLSTM: MAE=736.28, RMSE=933.50, R²=0.7114 (71.14%)

============================================================
Iteration 11/15 (Seed: 5678)
Config: hidden=64, layers=1, seq=7, batch=32, lr=0.002
============================================================

  Training BiLSTM...
    BiLSTM: MAE=733.09, RMSE=930.43, R²=0.7148 (71.48%)

============================================================
Iteration 12/15 (Seed: 5678)
Config: hidden=64, layers=1, seq=7, batch=32, lr=0.002
============================================================

  Training BiLSTM...
    BiLSTM: MAE=733.06, RMSE=935.48, R²=0.7117 (71.17%)

============================================================
Iteration 13/15 (Seed: 1234)
Config: hidden=64, layers=1, seq=7, batch=32, lr=0.002
============================================================

  Training BiLSTM...
    BiLSTM: MAE=752.60, RMSE=956.85, R²=0.6984 (69.84%)

============================================================
Iteration 14/15 (Seed: 42)
Config: hidden=64, layers=1, seq=7, batch=32, lr=0.002
============================================================

  Training BiLSTM...
    BiLSTM: MAE=732.51, RMSE=932.55, R²=0.7135 (71.35%)

============================================================
Iteration 15/15 (Seed: 9999)
Config: hidden=64, layers=1, seq=7, batch=32, lr=0.002
============================================================

  Training BiLSTM...
    BiLSTM: MAE=742.59, RMSE=944.91, R²=0.7058 (70.58%)

============================================================
최종 Best R²: 0.7184 (71.84%) - BiLSTM
============================================================

============================================================
앙상블 성능 계산 (11개 모델)
============================================================
  [단순평균] MAE=729.91, RMSE=927.79, R²=0.7164 (71.64%)
    모델 1: R²=0.7091, 가중치=0.091
    모델 2: R²=0.7031, 가중치=0.090
    모델 3: R²=0.7162, 가중치=0.092
    모델 4: R²=0.7171, 가중치=0.092
    모델 5: R²=0.7128, 가중치=0.091
    모델 6: R²=0.7136, 가중치=0.091
    모델 7: R²=0.7148, 가중치=0.091
    모델 8: R²=0.7117, 가중치=0.091
    모델 9: R²=0.6984, 가중치=0.089
    모델 10: R²=0.7135, 가중치=0.091
    모델 11: R²=0.7058, 가중치=0.090
  [가중평균] MAE=729.86, RMSE=927.73, R²=0.7164 (71.64%)

  ▶ 최적 앙상블: 가중평균 R²=0.7164 (71.64%)

목표 R² 미달성 - 하이브리드 앙상블 시도...

============================================================
V10: 하이브리드 앙상블 (BiLSTM + Gradient Boosting)
============================================================
Train: 3291, Val: 365, Test: 366

[1] BiLSTM 학습...
  BiLSTM R²: 0.7155 (71.55%)

[2] Gradient Boosting으로 잔차 학습...
  LightGBM 잔차 학습...
  BiLSTM + LightGBM R²: 0.6865 (68.65%)

최종 결과: BiLSTM R²=0.7155 (71.55%)

============================================================
최종 결과
============================================================

최적 모델: BiLSTM

하이퍼파라미터:
  hidden_dim: 64
  num_layers: 1
  seq_length: 14
  batch_size: 32
  lr: 0.001
  dropout: 0.1
  epochs: 800
  seed: 5678
  model: BiLSTM

성능 지표:
  MAE:  734.04 MWh
  MSE:  863811.44
  RMSE: 929.41 MWh
  R²:   0.7184 (71.84%)
  MAPE: 6.32%

============================================================
결과 그래프가 '/Users/ibkim/Ormi_1/power-demand-forecast/results/results.png'에 저장되었습니다.

모델이 '/Users/ibkim/Ormi_1/power-demand-forecast/best_model.pt'에 저장되었습니다.
