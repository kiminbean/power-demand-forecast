{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CatBoost v3.19 SMP Prediction Model Validation\n",
        "\n",
        "**Model Performance:**\n",
        "- MAPE: 5.28%\n",
        "- R²: 0.827\n",
        "- Features: 68\n",
        "\n",
        "**Purpose:** RTM (Real-Time Market) single-step prediction\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install catboost pandas numpy scikit-learn matplotlib seaborn -q\n",
        "print(\"Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/kiminbean/power-demand-forecast.git\n",
        "%cd power-demand-forecast\n",
        "print(\"Repository cloned!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "print(f\"Pandas: {pd.__version__}\")\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Model & Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model paths\n",
        "MODEL_DIR = Path(\"models/smp_v3_19_recent\")\n",
        "MODEL_PATH = MODEL_DIR / \"catboost_model.cbm\"\n",
        "METRICS_PATH = MODEL_DIR / \"metrics.json\"\n",
        "\n",
        "print(f\"Model exists: {MODEL_PATH.exists()}\")\n",
        "print(f\"Metrics exists: {METRICS_PATH.exists()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load metrics\n",
        "with open(METRICS_PATH) as f:\n",
        "    metrics = json.load(f)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"CatBoost v3.19 Training Metrics\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Test MAPE: {metrics['test_mape']:.2f}%\")\n",
        "print(f\"Test R²: {metrics['test_r2']:.4f}\")\n",
        "print(f\"Test MAE: {metrics['test_mae']:.2f}\")\n",
        "print(f\"Validation R²: {metrics['val_r2']:.4f}\")\n",
        "print(f\"Total samples: {metrics['n_samples']:,}\")\n",
        "print(f\"Features: {metrics['n_features']}\")\n",
        "print(f\"Best approach: {metrics['best_approach']}\")\n",
        "print(\"\\nBest hyperparameters:\")\n",
        "for k, v in metrics['best_params'].items():\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load CatBoost model\n",
        "model = CatBoostRegressor()\n",
        "model.load_model(str(MODEL_PATH))\n",
        "\n",
        "print(f\"Model loaded successfully!\")\n",
        "print(f\"Feature count: {model.feature_count_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load & Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load SMP data\n",
        "DATA_PATH = Path(\"data/smp/smp_5years_epsis.csv\")\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(f\"Data shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix hour 24 issue and parse datetime\n",
        "def fix_hour_24(ts):\n",
        "    if ' 24:00' in str(ts):\n",
        "        date_part = str(ts).replace(' 24:00', '')\n",
        "        return pd.to_datetime(date_part) + pd.Timedelta(days=1)\n",
        "    return pd.to_datetime(ts)\n",
        "\n",
        "df['datetime'] = df['timestamp'].apply(fix_hour_24)\n",
        "df = df[df['smp_mainland'] > 0].copy()\n",
        "df = df.sort_values('datetime').reset_index(drop=True)\n",
        "\n",
        "print(f\"Clean data shape: {df.shape}\")\n",
        "print(f\"Date range: {df['datetime'].min()} ~ {df['datetime'].max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Engineering (68 Features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature names (68 total)\n",
        "FEATURE_NAMES = [\n",
        "    # Time features (17)\n",
        "    'hour', 'hour_sin', 'hour_cos',\n",
        "    'dayofweek', 'dow_sin', 'dow_cos', 'is_weekend',\n",
        "    'month', 'month_sin', 'month_cos',\n",
        "    'doy_sin', 'doy_cos',\n",
        "    'is_summer', 'is_winter',\n",
        "    'peak_morning', 'peak_evening', 'off_peak',\n",
        "    # Lag features (12)\n",
        "    'smp_lag1', 'smp_lag2', 'smp_lag3', 'smp_lag4', 'smp_lag5', 'smp_lag6',\n",
        "    'smp_lag12', 'smp_lag24', 'smp_lag48', 'smp_lag72', 'smp_lag96', 'smp_lag168',\n",
        "    # Rolling statistics (24)\n",
        "    'smp_ma6', 'smp_std6', 'smp_min6', 'smp_max6',\n",
        "    'smp_ma12', 'smp_std12', 'smp_min12', 'smp_max12',\n",
        "    'smp_ma24', 'smp_std24', 'smp_min24', 'smp_max24',\n",
        "    'smp_ma48', 'smp_std48', 'smp_min48', 'smp_max48',\n",
        "    'smp_ma72', 'smp_std72', 'smp_min72', 'smp_max72',\n",
        "    'smp_ma168', 'smp_std168', 'smp_min168', 'smp_max168',\n",
        "    # EMA features (5) - v3.19\n",
        "    'smp_ema6', 'smp_ema12', 'smp_ema24', 'smp_ema48', 'smp_ema168',\n",
        "    # Diff features (3)\n",
        "    'smp_diff1', 'smp_diff24', 'smp_diff168',\n",
        "    # Ratio features (2)\n",
        "    'smp_lag1_vs_ma24', 'smp_lag1_vs_ma168',\n",
        "    # Range features (2)\n",
        "    'smp_range24', 'smp_range168',\n",
        "    # Momentum features (3) - v3.19\n",
        "    'smp_roc24', 'smp_roc168', 'smp_macd'\n",
        "]\n",
        "\n",
        "print(f\"Total features: {len(FEATURE_NAMES)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_features(df):\n",
        "    \"\"\"Create all 68 features for CatBoost v3.19\"\"\"\n",
        "    data = df.copy()\n",
        "    smp = data['smp_mainland']\n",
        "    dt = data['datetime']\n",
        "    \n",
        "    # Time features\n",
        "    data['hour'] = dt.dt.hour\n",
        "    data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
        "    data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
        "    \n",
        "    data['dayofweek'] = dt.dt.dayofweek\n",
        "    data['dow_sin'] = np.sin(2 * np.pi * data['dayofweek'] / 7)\n",
        "    data['dow_cos'] = np.cos(2 * np.pi * data['dayofweek'] / 7)\n",
        "    data['is_weekend'] = (data['dayofweek'] >= 5).astype(float)\n",
        "    \n",
        "    data['month'] = dt.dt.month\n",
        "    data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n",
        "    data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n",
        "    \n",
        "    doy = dt.dt.dayofyear\n",
        "    data['doy_sin'] = np.sin(2 * np.pi * doy / 365)\n",
        "    data['doy_cos'] = np.cos(2 * np.pi * doy / 365)\n",
        "    \n",
        "    data['is_summer'] = data['month'].isin([6, 7, 8]).astype(float)\n",
        "    data['is_winter'] = data['month'].isin([12, 1, 2]).astype(float)\n",
        "    \n",
        "    data['peak_morning'] = ((data['hour'] >= 9) & (data['hour'] <= 12)).astype(float)\n",
        "    data['peak_evening'] = ((data['hour'] >= 17) & (data['hour'] <= 21)).astype(float)\n",
        "    data['off_peak'] = ((data['hour'] >= 1) & (data['hour'] <= 6)).astype(float)\n",
        "    \n",
        "    # Lag features\n",
        "    for lag in [1, 2, 3, 4, 5, 6, 12, 24, 48, 72, 96, 168]:\n",
        "        data[f'smp_lag{lag}'] = smp.shift(lag)\n",
        "    \n",
        "    # Rolling statistics\n",
        "    for window in [6, 12, 24, 48, 72, 168]:\n",
        "        data[f'smp_ma{window}'] = smp.rolling(window).mean()\n",
        "        data[f'smp_std{window}'] = smp.rolling(window).std()\n",
        "        data[f'smp_min{window}'] = smp.rolling(window).min()\n",
        "        data[f'smp_max{window}'] = smp.rolling(window).max()\n",
        "    \n",
        "    # EMA features (v3.19)\n",
        "    for span in [6, 12, 24, 48, 168]:\n",
        "        data[f'smp_ema{span}'] = smp.ewm(span=span, adjust=False).mean()\n",
        "    \n",
        "    # Diff features\n",
        "    data['smp_diff1'] = smp.diff(1)\n",
        "    data['smp_diff24'] = smp.diff(24)\n",
        "    data['smp_diff168'] = smp.diff(168)\n",
        "    \n",
        "    # Ratio features\n",
        "    data['smp_lag1_vs_ma24'] = data['smp_lag1'] / data['smp_ma24']\n",
        "    data['smp_lag1_vs_ma168'] = data['smp_lag1'] / data['smp_ma168']\n",
        "    \n",
        "    # Range features\n",
        "    data['smp_range24'] = data['smp_max24'] - data['smp_min24']\n",
        "    data['smp_range168'] = data['smp_max168'] - data['smp_min168']\n",
        "    \n",
        "    # Momentum features (v3.19)\n",
        "    data['smp_roc24'] = smp.pct_change(24)\n",
        "    data['smp_roc168'] = smp.pct_change(168)\n",
        "    data['smp_macd'] = data['smp_ema12'] - data['smp_ema24']\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Create features\n",
        "df_features = create_features(df)\n",
        "print(f\"Features created: {df_features.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare final dataset\n",
        "df_clean = df_features.dropna().copy()\n",
        "\n",
        "X = df_clean[FEATURE_NAMES].values\n",
        "y = df_clean['smp_mainland'].values\n",
        "\n",
        "print(f\"Final dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
        "print(f\"Target range: {y.min():.2f} ~ {y.max():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data (same as training: 80% train, 20% test)\n",
        "split_idx = int(len(X) * 0.8)\n",
        "\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "print(f\"Train: {len(X_train)} samples\")\n",
        "print(f\"Test: {len(X_test)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"Validation Results (Test Set)\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"MAPE: {mape:.2f}%\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print()\n",
        "print(\"Comparison with Training Metrics:\")\n",
        "print(f\"  MAPE: {mape:.2f}% vs {metrics['test_mape']:.2f}% (training)\")\n",
        "print(f\"  R²: {r2:.4f} vs {metrics['test_r2']:.4f} (training)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot actual vs predicted\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. Time series comparison (last 168 hours)\n",
        "ax1 = axes[0, 0]\n",
        "n_plot = 168  # 1 week\n",
        "ax1.plot(y_test[-n_plot:], label='Actual', alpha=0.8)\n",
        "ax1.plot(y_pred[-n_plot:], label='Predicted', alpha=0.8)\n",
        "ax1.set_title('Last 168 Hours (1 Week)')\n",
        "ax1.set_xlabel('Hour')\n",
        "ax1.set_ylabel('SMP (won/kWh)')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Scatter plot\n",
        "ax2 = axes[0, 1]\n",
        "ax2.scatter(y_test, y_pred, alpha=0.3, s=10)\n",
        "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "ax2.set_title(f'Actual vs Predicted (R² = {r2:.4f})')\n",
        "ax2.set_xlabel('Actual SMP')\n",
        "ax2.set_ylabel('Predicted SMP')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Error distribution\n",
        "ax3 = axes[1, 0]\n",
        "errors = y_test - y_pred\n",
        "ax3.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
        "ax3.axvline(0, color='r', linestyle='--', lw=2)\n",
        "ax3.set_title(f'Error Distribution (MAE = {mae:.2f})')\n",
        "ax3.set_xlabel('Error (won/kWh)')\n",
        "ax3.set_ylabel('Frequency')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Percentage error distribution\n",
        "ax4 = axes[1, 1]\n",
        "pct_errors = (y_test - y_pred) / y_test * 100\n",
        "ax4.hist(pct_errors, bins=50, edgecolor='black', alpha=0.7)\n",
        "ax4.axvline(0, color='r', linestyle='--', lw=2)\n",
        "ax4.set_title(f'Percentage Error Distribution (MAPE = {mape:.2f}%)')\n",
        "ax4.set_xlabel('Error (%)')\n",
        "ax4.set_ylabel('Frequency')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('catboost_v319_validation.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "feature_importance = model.get_feature_importance()\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': FEATURE_NAMES,\n",
        "    'importance': feature_importance\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# Plot top 20 features\n",
        "plt.figure(figsize=(10, 8))\n",
        "top_n = 20\n",
        "plt.barh(range(top_n), importance_df['importance'].head(top_n).values[::-1])\n",
        "plt.yticks(range(top_n), importance_df['feature'].head(top_n).values[::-1])\n",
        "plt.xlabel('Importance')\n",
        "plt.title(f'Top {top_n} Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.savefig('catboost_v319_feature_importance.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 10 Features:\")\n",
        "print(importance_df.head(10).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Hourly Performance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze performance by hour\n",
        "test_df = df_clean.iloc[split_idx:].copy()\n",
        "test_df['predicted'] = y_pred\n",
        "test_df['error'] = test_df['smp_mainland'] - test_df['predicted']\n",
        "test_df['abs_pct_error'] = np.abs(test_df['error'] / test_df['smp_mainland']) * 100\n",
        "\n",
        "hourly_mape = test_df.groupby('hour')['abs_pct_error'].mean()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(hourly_mape.index, hourly_mape.values, edgecolor='black', alpha=0.7)\n",
        "plt.axhline(mape, color='r', linestyle='--', label=f'Overall MAPE: {mape:.2f}%')\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('MAPE (%)')\n",
        "plt.title('MAPE by Hour of Day')\n",
        "plt.xticks(range(24))\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('catboost_v319_hourly_mape.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nHourly MAPE:\")\n",
        "print(hourly_mape.round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"CatBoost v3.19 SMP Prediction Model - Validation Summary\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"Model Configuration:\")\n",
        "print(f\"  - Features: {len(FEATURE_NAMES)}\")\n",
        "print(f\"  - Best approach: {metrics['best_approach']}\")\n",
        "print(f\"  - Training samples: {metrics['n_samples']:,}\")\n",
        "print()\n",
        "print(\"Training Metrics:\")\n",
        "print(f\"  - MAPE: {metrics['test_mape']:.2f}%\")\n",
        "print(f\"  - R²: {metrics['test_r2']:.4f}\")\n",
        "print(f\"  - MAE: {metrics['test_mae']:.2f}\")\n",
        "print()\n",
        "print(\"Validation Metrics (Reproduced):\")\n",
        "print(f\"  - MAPE: {mape:.2f}%\")\n",
        "print(f\"  - R²: {r2:.4f}\")\n",
        "print(f\"  - MAE: {mae:.2f}\")\n",
        "print()\n",
        "print(\"Comparison with BiLSTM v3.2 (DAM model):\")\n",
        "print(f\"  - CatBoost v3.19: MAPE {mape:.2f}%, R² {r2:.4f}\")\n",
        "print(f\"  - BiLSTM v3.2:    MAPE 7.17%, R² 0.77\")\n",
        "print(f\"  - Improvement:    {7.17 - mape:.2f}%p MAPE, {r2 - 0.77:.4f} R²\")\n",
        "print()\n",
        "print(\"Purpose:\")\n",
        "print(\"  - RTM (Real-Time Market): CatBoost v3.19 (single-step)\")\n",
        "print(\"  - DAM (Day-Ahead Market): BiLSTM v3.2 (24-hour sequence)\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ]
}
