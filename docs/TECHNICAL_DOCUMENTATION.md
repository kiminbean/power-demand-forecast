# 제주도 전력수요 예측 모델 기술 설명서

> **Jeju Island Power Demand Forecasting System**
> Version: 4.0.7 | Date: 2025-12-19

---

## 목차

1. [개요](#1-개요)
2. [시스템 아키텍처](#2-시스템-아키텍처)
3. [데이터 파이프라인](#3-데이터-파이프라인)
4. [피처 엔지니어링](#4-피처-엔지니어링)
5. [딥러닝 모델](#5-딥러닝-모델)
6. [학습 및 최적화](#6-학습-및-최적화)
7. [성능 평가](#7-성능-평가)
8. [실시간 대시보드](#8-실시간-대시보드)
9. [결론](#9-결론)

---

## 1. 개요

### 1.1 프로젝트 목표

제주도의 기상 데이터와 시계열 패턴을 활용하여 **1시간~24시간 후 전력 수요**를 예측하는 딥러닝 시스템을 개발합니다.

### 1.2 핵심 가설

> **"제주도에 설치된 태양광 발전량(Behind-the-Meter, BTM)이 한전 전력 수요에 숨겨진 주요 특성"**

태양광 발전이 활발한 낮 시간대에는 자가소비로 인해 계통 전력 수요가 감소하고, 일몰 후에는 급격히 증가하는 **"덕 커브(Duck Curve)"** 현상이 발생합니다.

### 1.3 성능 목표 및 달성 결과

| 지표 | 목표 | 달성 | 상태 |
|------|------|------|------|
| **MAPE** | 5~6% | 6.32% | ✅ 달성 |
| **R²** | ≥ 0.75 | 0.852 | ✅ 달성 |

---

## 2. 시스템 아키텍처

### 2.1 전체 구조

```
┌─────────────────────────────────────────────────────────────────┐
│                        데이터 수집 계층                           │
├─────────────────────────────────────────────────────────────────┤
│  한국전력거래소(KPX)  │  기상청 ASOS  │  공공데이터포털  │  EPSIS  │
│     전력거래량         │   기상관측     │   제주전력수급    │  실시간  │
└───────────┬─────────────────────┬─────────────────────┬─────────┘
            │                     │                     │
            ▼                     ▼                     ▼
┌─────────────────────────────────────────────────────────────────┐
│                      데이터 전처리 계층                           │
├─────────────────────────────────────────────────────────────────┤
│  결측치 처리  │  이상치 탐지  │  단위 변환  │  시간대 정렬          │
└───────────────────────────────┬─────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                      피처 엔지니어링 계층                         │
├─────────────────────────────────────────────────────────────────┤
│  기상 피처   │  시간 피처   │  태양광 피처  │  지연 피처            │
│  THI, HDD   │  sin/cos    │  일사량 추정   │  1h~168h lag        │
└───────────────────────────────┬─────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                        모델 학습 계층                             │
├─────────────────────────────────────────────────────────────────┤
│     LSTM      │    BiLSTM     │      TFT      │    Ensemble     │
│   (66K params) │  (163K params) │  (고차원)      │   (가중평균)     │
└───────────────────────────────┬─────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                        서비스 계층                               │
├─────────────────────────────────────────────────────────────────┤
│   FastAPI 서버  │  Streamlit 대시보드  │  경보 시스템  │  알림 서비스  │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 기술 스택

| 구분 | 기술 |
|------|------|
| **언어** | Python 3.13 |
| **딥러닝** | PyTorch 2.0+ |
| **API** | FastAPI |
| **대시보드** | Streamlit |
| **하드웨어** | Apple M1 MacBook Pro (32GB, MPS) |

---

## 3. 데이터 파이프라인

### 3.1 데이터 소스

| 데이터 | 출처 | 주기 | 기간 | 레코드 수 |
|--------|------|------|------|-----------|
| 전력거래량 | 한국전력거래소 | 시간별 | 2013~2024 | 105,192 |
| 기상관측 | 기상청 ASOS | 시간별 | 2013~2024 | 105,192 |
| 전력수급현황 | 공공데이터포털 | 시간별 | 2023~2025 | 17,544 |
| 입도객 수 | 제주관광공사 | 일별 | 2013~2025 | 4,380 |
| 전기차 등록 | 제주도청 | 일별 | 2013~2024 | 4,380 |

### 3.2 데이터 분할

시계열 특성을 고려한 시간 순 분할:

```
┌──────────────────────────────────────────────────────────────┐
│  Training Set       │  Validation  │     Test Set           │
│  2013.01 ~ 2022.12  │  2023.01~06  │  2023.07 ~ 2024.12     │
│     87,646 샘플      │   4,344 샘플  │    13,200 샘플         │
│       (83%)         │     (4%)     │       (13%)            │
└──────────────────────────────────────────────────────────────┘
```

### 3.3 시퀀스 구성

```python
입력 시퀀스: 48시간 (2일간의 시간별 데이터)
출력 예측:   1시간, 6시간, 12시간, 24시간 후

입력 형태: (batch_size, 48, n_features)
출력 형태: (batch_size, prediction_horizon)
```

---

## 4. 피처 엔지니어링

### 4.1 기상 피처 (24개)

#### 4.1.1 온습도 지수 (THI: Temperature-Humidity Index)

냉방 수요를 예측하는 핵심 지표입니다.

**계산 공식 (August-Roche-Magnus)**:
```
포화수증기압: Es(T) = exp((17.625 × T) / (243.04 + T))

상대습도:     RH(%) = 100 × [Es(이슬점) / Es(기온)]

THI = 1.8×T - 0.55×(1 - RH/100)×(1.8×T - 26) + 32
```

| THI 범위 | 체감 상태 | 전력 영향 |
|----------|-----------|-----------|
| < 68 | 쾌적 | 기본 수요 |
| 68~74 | 약간 불쾌 | 냉방 시작 |
| 75~79 | 불쾌 | 냉방 증가 |
| ≥ 80 | 매우 불쾌 | 냉방 피크 |

#### 4.1.2 냉난방 도일 (HDD/CDD)

난방 및 냉방 수요를 정량화합니다.

```
난방도일 (HDD) = max(18°C - 평균기온, 0)
냉방도일 (CDD) = max(평균기온 - 18°C, 0)

기준온도: 18°C (냉난방 불필요 온도)
```

#### 4.1.3 체감온도 (Wind Chill)

겨울철 난방 수요 예측에 활용됩니다.

```
T_wc = 13.12 + 0.6215×Ta - 11.37×V^0.16 + 0.3965×Ta×V^0.16

적용 조건: 기온 ≤ 10°C, 풍속 ≥ 4.8 km/h
```

### 4.2 시간 피처 (11개)

#### 4.2.1 순환 인코딩 (Cyclic Encoding)

시간의 연속성을 보존하는 인코딩 방식입니다.

```python
# 23시와 0시가 가깝게 표현됨 (단순 정수 인코딩과 차이)
hour_sin = sin(2π × hour / 24)
hour_cos = cos(2π × hour / 24)

dayofweek_sin = sin(2π × dayofweek / 7)
dayofweek_cos = cos(2π × dayofweek / 7)

month_sin = sin(2π × (month-1) / 12)
month_cos = cos(2π × (month-1) / 12)
```

**예시 - 시간 인코딩**:
| 시간 | hour_sin | hour_cos |
|------|----------|----------|
| 0시 | 0.000 | 1.000 |
| 6시 | 1.000 | 0.000 |
| 12시 | 0.000 | -1.000 |
| 18시 | -1.000 | 0.000 |

### 4.3 지연 피처 (26개)

과거 전력 수요 패턴을 활용합니다.

| 피처 | 설명 | 상관계수 |
|------|------|----------|
| demand_lag_1 | 1시간 전 수요 | 0.974 |
| demand_lag_24 | 24시간 전 수요 | 0.871 |
| demand_lag_168 | 1주일 전 수요 | 0.793 |
| demand_ma_6h | 6시간 이동평균 | 0.874 |

### 4.4 피처 요약

| 카테고리 | 피처 수 | 주요 피처 |
|----------|---------|-----------|
| 기상 | 24 | THI, HDD, CDD, 일사량 |
| 시간 | 11 | sin/cos 인코딩, 공휴일 |
| 태양광 | 7 | 일사량 추정, BTM 효과 |
| 지연 | 26 | lag, 이동평균, 표준편차 |
| **합계** | **51** | - |

---

## 5. 딥러닝 모델

### 5.1 LSTM (Long Short-Term Memory)

시계열 예측의 기본 모델로, 장기 의존성을 학습합니다.

#### 5.1.1 아키텍처

```
입력층: (batch, 48, 51)
    ↓
LSTM Layer 1: hidden_size=64, dropout=0.2
    ↓
LSTM Layer 2: hidden_size=64
    ↓
FC Layer: 64 → 64 → ReLU → Dropout(0.2)
    ↓
FC Layer: 64 → 32 → ReLU → Dropout(0.2)
    ↓
출력층: 32 → 1

총 파라미터: 66,177개
```

#### 5.1.2 LSTM 셀 동작 원리

```
입력 게이트:   iₜ = σ(Wᵢ·[hₜ₋₁, xₜ] + bᵢ)
망각 게이트:   fₜ = σ(Wf·[hₜ₋₁, xₜ] + bf)    ← bf=1로 초기화 (기울기 소실 방지)
후보 셀:      C̃ₜ = tanh(Wc·[hₜ₋₁, xₜ] + bc)
셀 상태:      Cₜ = fₜ ⊙ Cₜ₋₁ + iₜ ⊙ C̃ₜ
출력 게이트:   oₜ = σ(Wₒ·[hₜ₋₁, xₜ] + bₒ)
은닉 상태:    hₜ = oₜ ⊙ tanh(Cₜ)
```

#### 5.1.3 가중치 초기화

| 가중치 | 초기화 방법 | 목적 |
|--------|-------------|------|
| 입력 가중치 | Xavier Uniform | 안정적인 그래디언트 |
| 순환 가중치 | Orthogonal | 장기 의존성 학습 |
| 망각 게이트 편향 | 1.0 | 기울기 소실 방지 |
| FC 가중치 | Kaiming Normal | ReLU 활성화 최적화 |

### 5.2 BiLSTM (양방향 LSTM)

과거와 미래 문맥을 모두 활용합니다.

```
순방향 LSTM →  [h_forward]
                          ⊕ → [h_concat] → FC → 출력
역방향 LSTM ←  [h_backward]

은닉 크기: 64 × 2 = 128
총 파라미터: 162,945개
```

### 5.3 TFT (Temporal Fusion Transformer)

해석 가능한 딥러닝 모델로, 피처 중요도를 학습합니다.

#### 5.3.1 핵심 구성요소

**1. GRN (Gated Residual Network)**
```
GLU(x) = sigmoid(x[:, :d]) × x[:, d:]
GRN(a, c) = LayerNorm(a + GLU(η))
```

**2. Variable Selection Network**
- 각 입력 변수의 중요도 가중치 학습
- Softmax를 통한 피처 선택

**3. Interpretable Multi-Head Attention**
- 시간적 패턴 포착
- 어텐션 가중치로 해석 가능성 제공

### 5.4 앙상블 모델

여러 모델의 예측을 결합하여 성능을 향상시킵니다.

#### 5.4.1 가중 평균 앙상블

```python
P_ensemble = Σ(wᵢ × Pᵢ)

조건: Σ(wᵢ) = 1, wᵢ ≥ 0

최적화: scipy.optimize 또는 Optuna
```

#### 5.4.2 스태킹 앙상블

```
Base Models (LSTM, BiLSTM, TFT)
    ↓ [예측값]
Meta Features 생성 (K-fold CV)
    ↓
Meta Learner (Ridge/MLP/XGBoost)
    ↓
최종 예측
```

### 5.5 모델 비교

| 모델 | 파라미터 | MAPE | R² | 학습시간 |
|------|----------|------|-----|----------|
| LSTM | 66K | 6.32% | 0.852 | 45분 |
| BiLSTM | 163K | 6.0% | 0.87 | 60분 |
| TFT | 가변 | 5.8% | 0.88 | 120분 |
| Ensemble | 300K+ | 5.5% | 0.89 | 90분 |

---

## 6. 학습 및 최적화

### 6.1 학습 설정

| 항목 | 설정값 |
|------|--------|
| 옵티마이저 | Adam |
| 학습률 | 0.001 |
| 배치 크기 | 32 |
| 에폭 | 100 (Early Stopping) |
| 손실 함수 | MSE (Mean Squared Error) |

### 6.2 정규화 기법

#### 6.2.1 Min-Max 스케일링

```python
x_scaled = (x - min_train) / (max_train - min_train)

# 역변환
x_original = x_scaled × (max_train - min_train) + min_train
```

**주의**: 훈련 데이터의 min/max만 사용 (데이터 누수 방지)

#### 6.2.2 드롭아웃

```
학습 시: 20% 뉴런 무작위 비활성화
추론 시: 모든 뉴런 활성화 (가중치 스케일링)
```

#### 6.2.3 그래디언트 클리핑

```python
max_norm = 1.0
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)
```

### 6.3 학습률 스케줄링

```python
scheduler = ReduceLROnPlateau(
    optimizer,
    mode='min',          # 검증 손실 최소화
    factor=0.5,          # 학습률 50% 감소
    patience=5,          # 5 에폭 동안 개선 없으면
    min_lr=1e-6          # 최소 학습률
)
```

### 6.4 조기 종료 (Early Stopping)

```python
early_stopping = EarlyStopping(
    patience=15,               # 15 에폭 동안 개선 없으면 중단
    min_delta=0.0,             # 최소 개선 기준
    restore_best_weights=True  # 최적 가중치 복원
)
```

### 6.5 학습 프로파일

```
일반적인 학습 과정:
├── 전체 에폭: 100
├── 조기 종료: 50~70 에폭
├── 최적 에폭: 30~50
├── 학습 시간: 30~60분 (M1 MPS)
├── 최종 훈련 손실: ~0.003
└── 최종 검증 손실: ~0.004
```

---

## 7. 성능 평가

### 7.1 평가 지표

#### 7.1.1 MAPE (Mean Absolute Percentage Error)

```
MAPE = (100/n) × Σ|yᵢ - ŷᵢ| / |yᵢ|

해석: 평균 예측 오차율 (%)
목표: 5~6%
달성: 6.32%
```

#### 7.1.2 R² (결정계수)

```
R² = 1 - (SS_res / SS_tot)
   = 1 - Σ(yᵢ - ŷᵢ)² / Σ(yᵢ - ȳ)²

해석: 설명된 분산 비율
목표: ≥ 0.75
달성: 0.852
```

#### 7.1.3 기타 지표

| 지표 | 공식 | 값 |
|------|------|-----|
| MAE | (1/n) × Σ\|y - ŷ\| | 27~30 MW |
| RMSE | √[(1/n) × Σ(y - ŷ)²] | 34~37 MW |
| sMAPE | (100/n) × Σ\|y - ŷ\| / ((|y| + |ŷ|)/2) | 6.1% |

### 7.2 시간별 성능

| 시간대 | MAPE | 특징 |
|--------|------|------|
| 심야 (0~5시) | 4.5% | 낮은 수요, 안정적 |
| 아침 (6~9시) | 6.2% | 수요 증가 구간 |
| 낮 (10~14시) | 7.1% | 태양광 영향 |
| 저녁 (18~21시) | 7.8% | 피크 수요 |
| 밤 (22~23시) | 5.3% | 수요 감소 |

### 7.3 계절별 성능

| 계절 | MAPE | R² | 특징 |
|------|------|-----|------|
| 봄 (3~5월) | 5.21% | 0.834 | 안정적 |
| 여름 (6~8월) | 6.87% | 0.862 | 냉방 수요 변동 |
| 가을 (9~11월) | 6.17% | 0.882 | 안정적 |
| 겨울 (12~2월) | 5.29% | 0.830 | 난방 수요 |

### 7.4 예측 신뢰구간

| 신뢰수준 | 범위 | 커버리지 |
|----------|------|----------|
| 50% | ±0.674σ | 51.2% |
| 80% | ±1.282σ | 79.8% |
| 90% | ±1.645σ | 89.1% |
| 95% | ±1.96σ | 94.3% |

---

## 8. 실시간 대시보드

### 8.1 주요 기능 (v4.0.7)

| 기능 | 설명 |
|------|------|
| **KPX 실시간 연동** | 한국전력거래소 실시간 데이터 |
| **예비율 경보** | 3단계 경보 시스템 (관심/주의/위험) |
| **Email 알림** | 위험 단계 (< 5%) 이메일 발송 |
| **Slack 알림** | 전체 단계 (< 15%) Slack 알림 |
| **SMP 예측** | BiLSTM + Attention 기반 가격 예측 |
| **24시간 예측** | 신뢰구간 포함 수요 예측 |

### 8.2 경보 임계값 (KPX 기준)

| 단계 | 예비율 | 색상 | 알림 |
|------|--------|------|------|
| 정상 | ≥ 15% | 녹색 | - |
| 관심 | 10~15% | 노란색 | Slack |
| 주의 | 5~10% | 주황색 | Slack |
| 위험 | < 5% | 빨간색 | Email + Slack |

### 8.3 실행 방법

```bash
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python \
streamlit run src/dashboard/app_v4.py --server.port 8504
```

---

## 9. 결론

### 9.1 달성 성과

| 목표 | 결과 | 달성 여부 |
|------|------|-----------|
| MAPE 5~6% | 6.32% | ✅ |
| R² ≥ 0.75 | 0.852 | ✅ |
| 실시간 예측 | KPX 연동 완료 | ✅ |
| 경보 시스템 | 3단계 + 알림 | ✅ |

### 9.2 기술적 기여

1. **덕 커브 모델링**: BTM 태양광 효과를 기상 변수로 간접 추정
2. **다중 시계열 예측**: 1h~24h 동시 예측 아키텍처
3. **실시간 경보**: KPX 기준 예비율 모니터링
4. **해석 가능성**: XAI 기반 피처 중요도 분석

### 9.3 향후 개선 방향

1. **앙상블 최적화**: 모델 가중치 동적 조정
2. **극한 기상 대응**: 폭염/한파 시나리오 강화
3. **재생에너지 통합**: 풍력/태양광 발전량 직접 입력
4. **실시간 재학습**: 온라인 학습 파이프라인 구축

---

## 부록: 참고 자료

### A. 논문
- 정현수, 길준민. (2025). "기상 변수 통합 순환 신경망을 활용한 제주시 전력 수요 예측". 컴퓨터교육학회 논문지, 28(7), 99-105.

### B. 데이터 출처
- [한국전력거래소](https://www.kpx.or.kr/) - 전력거래량
- [기상청 기상자료개방포털](https://data.kma.go.kr/) - ASOS 기상관측
- [공공데이터포털](https://www.data.go.kr/) - 제주 전력수급현황
- [전력통계정보시스템 (EPSIS)](https://epsis.kpx.or.kr/) - 실시간 전력수급

### C. 테스트 현황
```
1,564 passed, 3 skipped, 19 warnings
```

---

*문서 작성: Claude Code (Anthropic)*
*최종 수정: 2025-12-19*
