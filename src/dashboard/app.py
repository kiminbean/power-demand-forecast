"""
ëŒ€ì‹œë³´ë“œ UI (Task 14)
====================
ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ì‹œê°í™” ëŒ€ì‹œë³´ë“œ
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta, date
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
import logging

logger = logging.getLogger(__name__)


# ============================================================================
# Configuration
# ============================================================================

@dataclass
class DashboardConfig:
    """ëŒ€ì‹œë³´ë“œ ì„¤ì •"""
    api_url: str = "http://localhost:8000"
    refresh_interval: int = 60  # seconds
    default_location: str = "jeju"
    theme: str = "light"
    chart_height: int = 400
    max_history_days: int = 365


def get_config() -> DashboardConfig:
    """ì„¤ì • ë¡œë“œ"""
    return DashboardConfig()


# ============================================================================
# Data Fetchers
# ============================================================================

class DataFetcher:
    """ë°ì´í„° ìˆ˜ì§‘ê¸°"""

    def __init__(self, api_url: str):
        self.api_url = api_url
        self._cache: Dict[str, Any] = {}

    def get_predictions(
        self,
        location: str = "jeju",
        horizons: List[str] = None,
        model_type: str = "ensemble"
    ) -> Optional[Dict]:
        """ì˜ˆì¸¡ ë°ì´í„° ì¡°íšŒ"""
        if horizons is None:
            horizons = ["1h", "6h", "24h"]

        try:
            response = requests.post(
                f"{self.api_url}/predict",
                json={
                    "location": location,
                    "horizons": horizons,
                    "model_type": model_type
                },
                timeout=10
            )
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"Prediction fetch failed: {e}")
            return None

    def get_historical_data(
        self,
        location: str,
        start_date: str,
        end_date: str,
        resolution: str = "hourly"
    ) -> Optional[Dict]:
        """ê³¼ê±° ë°ì´í„° ì¡°íšŒ"""
        try:
            response = requests.get(
                f"{self.api_url}/data/historical",
                params={
                    "location": location,
                    "start_date": start_date,
                    "end_date": end_date,
                    "resolution": resolution
                },
                timeout=10
            )
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"Historical data fetch failed: {e}")
            return None

    def get_health(self) -> Optional[Dict]:
        """ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get(f"{self.api_url}/health", timeout=5)
            response.raise_for_status()
            return response.json()
        except Exception:
            return None

    def get_models(self) -> Optional[Dict]:
        """ëª¨ë¸ ëª©ë¡"""
        try:
            response = requests.get(f"{self.api_url}/models", timeout=5)
            response.raise_for_status()
            return response.json()
        except Exception:
            return None

    def get_metrics(self) -> Optional[Dict]:
        """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        try:
            response = requests.get(f"{self.api_url}/metrics", timeout=5)
            response.raise_for_status()
            return response.json()
        except Exception:
            return None


# ============================================================================
# Mock Data Generator (for offline mode)
# ============================================================================

class MockDataGenerator:
    """ì˜¤í”„ë¼ì¸ ëª¨ë“œìš© ëª¨ì˜ ë°ì´í„° ìƒì„±ê¸°"""

    @staticmethod
    def generate_predictions(
        horizons: List[str] = None
    ) -> Dict:
        """ì˜ˆì¸¡ ë°ì´í„° ìƒì„±"""
        if horizons is None:
            horizons = ["1h", "6h", "24h"]

        now = datetime.now()
        predictions = []

        for horizon in horizons:
            hours = int(horizon.replace("h", ""))
            target_time = now + timedelta(hours=hours)

            # ì‹œê°„ëŒ€ë³„ ìˆ˜ìš” íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜
            hour = target_time.hour
            base_demand = 800 + 200 * np.sin(hour * np.pi / 12)
            variation = np.random.randn() * 30

            pred_value = base_demand + variation
            std = 30 + hours * 2

            predictions.append({
                "timestamp": target_time.isoformat(),
                "horizon": horizon,
                "prediction": round(pred_value, 2),
                "lower_bound": round(pred_value - 1.96 * std, 2),
                "upper_bound": round(pred_value + 1.96 * std, 2),
                "confidence": round(0.95 - hours * 0.01, 3)
            })

        return {
            "request_id": "mock123",
            "location": "jeju",
            "model_type": "ensemble",
            "created_at": now.isoformat(),
            "predictions": predictions
        }

    @staticmethod
    def generate_historical_data(
        start_date: date,
        end_date: date,
        resolution: str = "hourly"
    ) -> Dict:
        """ê³¼ê±° ë°ì´í„° ìƒì„±"""
        data = []
        current = datetime.combine(start_date, datetime.min.time())
        end = datetime.combine(end_date, datetime.max.time())

        delta = timedelta(hours=1) if resolution == "hourly" else timedelta(days=1)

        while current <= end:
            hour = current.hour
            day_of_year = current.timetuple().tm_yday

            # ê³„ì ˆ íŒ¨í„´
            seasonal = 100 * np.sin(2 * np.pi * day_of_year / 365)
            # ì¼ê°„ íŒ¨í„´
            daily = 200 * np.sin((hour - 6) * np.pi / 12)
            # ê¸°ë³¸ ìˆ˜ìš”
            base = 850

            demand = base + seasonal + daily + np.random.randn() * 30
            temp = 15 + 10 * np.sin(2 * np.pi * day_of_year / 365) + np.random.randn() * 3
            humidity = 60 + np.random.randn() * 10

            data.append({
                "timestamp": current.isoformat(),
                "demand": round(demand, 2),
                "temperature": round(temp, 1),
                "humidity": round(humidity, 1)
            })
            current += delta

        return {
            "location": "jeju",
            "start_date": start_date.isoformat(),
            "end_date": end_date.isoformat(),
            "data": data,
            "count": len(data)
        }


# ============================================================================
# Chart Components
# ============================================================================

class ChartFactory:
    """ì°¨íŠ¸ ìƒì„± íŒ©í† ë¦¬"""

    @staticmethod
    def create_prediction_chart(predictions: List[Dict], height: int = 400) -> go.Figure:
        """ì˜ˆì¸¡ ì°¨íŠ¸ ìƒì„±"""
        if not predictions:
            return go.Figure()

        timestamps = [p["timestamp"] for p in predictions]
        values = [p["prediction"] for p in predictions]
        lower = [p.get("lower_bound", p["prediction"] - 50) for p in predictions]
        upper = [p.get("upper_bound", p["prediction"] + 50) for p in predictions]

        fig = go.Figure()

        # ì‹ ë¢° êµ¬ê°„
        fig.add_trace(go.Scatter(
            x=timestamps + timestamps[::-1],
            y=upper + lower[::-1],
            fill="toself",
            fillcolor="rgba(0, 100, 255, 0.2)",
            line=dict(color="rgba(255,255,255,0)"),
            name="95% ì‹ ë¢°êµ¬ê°„",
            showlegend=True
        ))

        # ì˜ˆì¸¡ê°’
        fig.add_trace(go.Scatter(
            x=timestamps,
            y=values,
            mode="lines+markers",
            name="ì˜ˆì¸¡ê°’",
            line=dict(color="blue", width=2),
            marker=dict(size=8)
        ))

        fig.update_layout(
            title="ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡",
            xaxis_title="ì‹œê°„",
            yaxis_title="ìˆ˜ìš” (MW)",
            height=height,
            legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01)
        )

        return fig

    @staticmethod
    def create_historical_chart(
        data: List[Dict],
        height: int = 400
    ) -> go.Figure:
        """ê³¼ê±° ë°ì´í„° ì°¨íŠ¸ ìƒì„±"""
        if not data:
            return go.Figure()

        df = pd.DataFrame(data)
        df["timestamp"] = pd.to_datetime(df["timestamp"])

        fig = make_subplots(
            rows=2, cols=1,
            shared_xaxes=True,
            vertical_spacing=0.1,
            subplot_titles=("ì „ë ¥ ìˆ˜ìš”", "ê¸°ì˜¨")
        )

        # ì „ë ¥ ìˆ˜ìš”
        fig.add_trace(
            go.Scatter(
                x=df["timestamp"],
                y=df["demand"],
                mode="lines",
                name="ìˆ˜ìš”",
                line=dict(color="blue")
            ),
            row=1, col=1
        )

        # ê¸°ì˜¨
        if "temperature" in df.columns:
            fig.add_trace(
                go.Scatter(
                    x=df["timestamp"],
                    y=df["temperature"],
                    mode="lines",
                    name="ê¸°ì˜¨",
                    line=dict(color="red")
                ),
                row=2, col=1
            )

        fig.update_layout(height=height, showlegend=True)
        fig.update_yaxes(title_text="MW", row=1, col=1)
        fig.update_yaxes(title_text="Â°C", row=2, col=1)

        return fig

    @staticmethod
    def create_demand_pattern_chart(
        data: List[Dict],
        height: int = 400
    ) -> go.Figure:
        """ìˆ˜ìš” íŒ¨í„´ ë¶„ì„ ì°¨íŠ¸"""
        if not data:
            return go.Figure()

        df = pd.DataFrame(data)
        df["timestamp"] = pd.to_datetime(df["timestamp"])
        df["hour"] = df["timestamp"].dt.hour
        df["day_of_week"] = df["timestamp"].dt.dayofweek

        # ì‹œê°„ëŒ€ë³„ í‰ê· 
        hourly_avg = df.groupby("hour")["demand"].mean()

        fig = go.Figure()

        fig.add_trace(go.Bar(
            x=hourly_avg.index,
            y=hourly_avg.values,
            name="ì‹œê°„ëŒ€ë³„ í‰ê· ",
            marker_color="steelblue"
        ))

        fig.update_layout(
            title="ì‹œê°„ëŒ€ë³„ í‰ê·  ì „ë ¥ ìˆ˜ìš”",
            xaxis_title="ì‹œê°„",
            yaxis_title="í‰ê·  ìˆ˜ìš” (MW)",
            height=height
        )

        return fig

    @staticmethod
    def create_model_comparison_chart(
        models: List[Dict],
        height: int = 300
    ) -> go.Figure:
        """ëª¨ë¸ ë¹„êµ ì°¨íŠ¸"""
        if not models:
            return go.Figure()

        names = [m["name"] for m in models]
        rmse_values = [m.get("metrics", {}).get("rmse", 0) for m in models]
        mape_values = [m.get("metrics", {}).get("mape", 0) for m in models]

        fig = make_subplots(rows=1, cols=2, subplot_titles=("RMSE", "MAPE (%)"))

        fig.add_trace(
            go.Bar(x=names, y=rmse_values, name="RMSE", marker_color="steelblue"),
            row=1, col=1
        )

        fig.add_trace(
            go.Bar(x=names, y=mape_values, name="MAPE", marker_color="indianred"),
            row=1, col=2
        )

        fig.update_layout(height=height, showlegend=False)

        return fig

    @staticmethod
    def create_gauge_chart(
        value: float,
        title: str,
        max_value: float = 100,
        height: int = 200
    ) -> go.Figure:
        """ê²Œì´ì§€ ì°¨íŠ¸ ìƒì„±"""
        fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=value,
            title={"text": title},
            gauge={
                "axis": {"range": [0, max_value]},
                "bar": {"color": "darkblue"},
                "steps": [
                    {"range": [0, max_value * 0.5], "color": "lightgreen"},
                    {"range": [max_value * 0.5, max_value * 0.8], "color": "yellow"},
                    {"range": [max_value * 0.8, max_value], "color": "red"}
                ]
            }
        ))

        fig.update_layout(height=height)
        return fig


# ============================================================================
# Dashboard Components
# ============================================================================

class DashboardComponents:
    """ëŒ€ì‹œë³´ë“œ ì»´í¬ë„ŒíŠ¸"""

    @staticmethod
    def render_header():
        """í—¤ë” ë Œë”ë§"""
        st.title("ğŸ”Œ ì œì£¼ë„ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ")
        st.markdown("---")

    @staticmethod
    def render_sidebar(config: DashboardConfig) -> Dict:
        """ì‚¬ì´ë“œë°” ë Œë”ë§"""
        st.sidebar.title("âš™ï¸ ì„¤ì •")

        # ìœ„ì¹˜ ì„ íƒ
        location = st.sidebar.selectbox(
            "ìœ„ì¹˜",
            ["jeju", "seoul", "busan"],
            index=0
        )

        # ëª¨ë¸ ì„ íƒ
        model_type = st.sidebar.selectbox(
            "ëª¨ë¸",
            ["ensemble", "lstm", "tft"],
            index=0
        )

        # ì˜ˆì¸¡ ì‹œê°„ëŒ€
        horizons = st.sidebar.multiselect(
            "ì˜ˆì¸¡ ì‹œê°„ëŒ€",
            ["1h", "6h", "12h", "24h", "48h"],
            default=["1h", "6h", "24h"]
        )

        # ë‚ ì§œ ë²”ìœ„
        st.sidebar.subheader("ê³¼ê±° ë°ì´í„°")
        date_range = st.sidebar.date_input(
            "ë‚ ì§œ ë²”ìœ„",
            value=(
                datetime.now().date() - timedelta(days=7),
                datetime.now().date()
            )
        )

        # í•´ìƒë„
        resolution = st.sidebar.radio(
            "í•´ìƒë„",
            ["hourly", "daily"],
            horizontal=True
        )

        st.sidebar.markdown("---")
        st.sidebar.info(f"API: {config.api_url}")

        return {
            "location": location,
            "model_type": model_type,
            "horizons": horizons,
            "date_range": date_range,
            "resolution": resolution
        }

    @staticmethod
    def render_status_cards(health: Optional[Dict], metrics: Optional[Dict]):
        """ìƒíƒœ ì¹´ë“œ ë Œë”ë§"""
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            status = health.get("status", "unknown") if health else "offline"
            color = "ğŸŸ¢" if status == "healthy" else "ğŸ”´"
            st.metric("ìƒíƒœ", f"{color} {status}")

        with col2:
            uptime = health.get("uptime", 0) if health else 0
            hours = uptime / 3600
            st.metric("ì—…íƒ€ì„", f"{hours:.1f}h")

        with col3:
            total_preds = metrics.get("total_predictions", 0) if metrics else 0
            st.metric("ì´ ì˜ˆì¸¡ ìˆ˜", total_preds)

        with col4:
            models_loaded = health.get("models_loaded", 0) if health else 0
            st.metric("ë¡œë“œëœ ëª¨ë¸", models_loaded)

    @staticmethod
    def render_prediction_section(
        predictions: Optional[Dict],
        chart_factory: ChartFactory,
        height: int = 400
    ):
        """ì˜ˆì¸¡ ì„¹ì…˜ ë Œë”ë§"""
        st.subheader("ğŸ“ˆ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡")

        if predictions and predictions.get("predictions"):
            # ì˜ˆì¸¡ ì°¨íŠ¸
            fig = chart_factory.create_prediction_chart(
                predictions["predictions"],
                height=height
            )
            st.plotly_chart(fig, use_container_width=True)

            # ì˜ˆì¸¡ í…Œì´ë¸”
            with st.expander("ìƒì„¸ ë°ì´í„°"):
                df = pd.DataFrame(predictions["predictions"])
                st.dataframe(df)

            # ë©”íƒ€ë°ì´í„°
            st.caption(
                f"ëª¨ë¸: {predictions.get('model_type')} | "
                f"ìƒì„±: {predictions.get('created_at')} | "
                f"ID: {predictions.get('request_id')}"
            )
        else:
            st.warning("ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    @staticmethod
    def render_historical_section(
        historical_data: Optional[Dict],
        chart_factory: ChartFactory,
        height: int = 400
    ):
        """ê³¼ê±° ë°ì´í„° ì„¹ì…˜ ë Œë”ë§"""
        st.subheader("ğŸ“Š ê³¼ê±° ë°ì´í„°")

        if historical_data and historical_data.get("data"):
            # ê³¼ê±° ë°ì´í„° ì°¨íŠ¸
            tab1, tab2 = st.tabs(["ì‹œê³„ì—´", "íŒ¨í„´ ë¶„ì„"])

            with tab1:
                fig = chart_factory.create_historical_chart(
                    historical_data["data"],
                    height=height
                )
                st.plotly_chart(fig, use_container_width=True)

            with tab2:
                fig = chart_factory.create_demand_pattern_chart(
                    historical_data["data"],
                    height=height
                )
                st.plotly_chart(fig, use_container_width=True)

            st.caption(f"ë°ì´í„° ìˆ˜: {historical_data.get('count', 0)}ê°œ")
        else:
            st.warning("ê³¼ê±° ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    @staticmethod
    def render_model_section(
        models: Optional[Dict],
        chart_factory: ChartFactory
    ):
        """ëª¨ë¸ ì„¹ì…˜ ë Œë”ë§"""
        st.subheader("ğŸ¤– ëª¨ë¸ ì •ë³´")

        if models and models.get("models"):
            # ëª¨ë¸ ë¹„êµ ì°¨íŠ¸
            fig = chart_factory.create_model_comparison_chart(
                models["models"],
                height=300
            )
            st.plotly_chart(fig, use_container_width=True)

            # ëª¨ë¸ ìƒì„¸
            with st.expander("ëª¨ë¸ ìƒì„¸ ì •ë³´"):
                for model in models["models"]:
                    st.write(f"**{model['name']}** ({model['type']})")
                    st.write(f"- ë²„ì „: {model.get('version', 'N/A')}")
                    st.write(f"- ìƒíƒœ: {model.get('status', 'N/A')}")
                    st.write(f"- ë©”íŠ¸ë¦­: {model.get('metrics', {})}")
                    st.markdown("---")
        else:
            st.warning("ëª¨ë¸ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# ============================================================================
# Main Dashboard
# ============================================================================

class Dashboard:
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ í´ë˜ìŠ¤"""

    def __init__(self, config: DashboardConfig = None):
        self.config = config or get_config()
        self.fetcher = DataFetcher(self.config.api_url)
        self.mock_generator = MockDataGenerator()
        self.chart_factory = ChartFactory()
        self.components = DashboardComponents()
        self._use_mock = False

    def check_api_status(self) -> bool:
        """API ìƒíƒœ í™•ì¸"""
        health = self.fetcher.get_health()
        return health is not None

    def run(self):
        """ëŒ€ì‹œë³´ë“œ ì‹¤í–‰"""
        # í˜ì´ì§€ ì„¤ì •
        st.set_page_config(
            page_title="ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡",
            page_icon="ğŸ”Œ",
            layout="wide"
        )

        # í—¤ë”
        self.components.render_header()

        # ì‚¬ì´ë“œë°”
        settings = self.components.render_sidebar(self.config)

        # API ìƒíƒœ í™•ì¸
        if not self.check_api_status():
            st.warning("âš ï¸ API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self._use_mock = True

        # ë°ì´í„° ë¡œë“œ
        if self._use_mock:
            health = {"status": "mock", "uptime": 0, "models_loaded": 0}
            metrics = {"total_predictions": 0}
            predictions = self.mock_generator.generate_predictions(settings["horizons"])
            historical = self.mock_generator.generate_historical_data(
                settings["date_range"][0],
                settings["date_range"][1],
                settings["resolution"]
            )
            models = {
                "models": [
                    {"name": "lstm_v1", "type": "lstm", "metrics": {"rmse": 45, "mape": 3.5}, "status": "mock"},
                    {"name": "ensemble_v1", "type": "ensemble", "metrics": {"rmse": 40, "mape": 3.0}, "status": "mock"}
                ],
                "count": 2
            }
        else:
            health = self.fetcher.get_health()
            metrics = self.fetcher.get_metrics()
            predictions = self.fetcher.get_predictions(
                location=settings["location"],
                horizons=settings["horizons"],
                model_type=settings["model_type"]
            )
            historical = self.fetcher.get_historical_data(
                location=settings["location"],
                start_date=settings["date_range"][0].isoformat(),
                end_date=settings["date_range"][1].isoformat(),
                resolution=settings["resolution"]
            )
            models = self.fetcher.get_models()

        # ìƒíƒœ ì¹´ë“œ
        self.components.render_status_cards(health, metrics)

        st.markdown("---")

        # ë©”ì¸ ì»¨í…ì¸ 
        col1, col2 = st.columns([2, 1])

        with col1:
            self.components.render_prediction_section(
                predictions,
                self.chart_factory,
                self.config.chart_height
            )

        with col2:
            self.components.render_model_section(
                models,
                self.chart_factory
            )

        st.markdown("---")

        # ê³¼ê±° ë°ì´í„° ì„¹ì…˜
        self.components.render_historical_section(
            historical,
            self.chart_factory,
            self.config.chart_height
        )

        # í‘¸í„°
        st.markdown("---")
        st.caption(
            f"ğŸ“… ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | "
            f"ğŸ”„ ìë™ ìƒˆë¡œê³ ì¹¨: {self.config.refresh_interval}ì´ˆ"
        )


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    dashboard = Dashboard()
    dashboard.run()


if __name__ == "__main__":
    main()
