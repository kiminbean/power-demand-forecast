"""
ì œì£¼ë„ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ (API ì—°ë™ ë²„ì „)
==============================================

FastAPI ì„œë²„ì™€ ì—°ë™í•˜ì—¬ ì‹¤ì‹œê°„ ì˜ˆì¸¡ì„ ì œê³µí•˜ëŠ” Streamlit ëŒ€ì‹œë³´ë“œ

ì£¼ìš” ê¸°ëŠ¥:
1. ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì°¨íŠ¸ (24ì‹œê°„) - API ì—°ë™
2. ê¸°ìƒ ì¡°ê±´ ì…ë ¥ ì¸í„°í˜ì´ìŠ¤
3. ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ (í­ì—¼/í•œíŒŒ)
4. ê³¼ê±° ë°ì´í„° ë¹„êµ
5. ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ

Usage:
    # API ì„œë²„ ë¨¼ì € ì‹¤í–‰
    uvicorn api.main:app --host 0.0.0.0 --port 8000

    # ëŒ€ì‹œë³´ë“œ ì‹¤í–‰
    streamlit run src/dashboard/app.py

Author: Power Demand Forecast Team
Date: 2025-12
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta, date
from typing import Dict, List, Optional, Any, Tuple
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
import json
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / "src"))


# ============================================================================
# í˜ì´ì§€ ì„¤ì •
# ============================================================================

st.set_page_config(
    page_title="ì œì£¼ë„ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡",
    page_icon="âš¡",
    layout="wide",
    initial_sidebar_state="expanded"
)


# ============================================================================
# ìŠ¤íƒ€ì¼
# ============================================================================

st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E3A8A;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #64748B;
        margin-bottom: 2rem;
    }
    .api-connected {
        background-color: #D1FAE5;
        color: #065F46;
        padding: 0.5rem 1rem;
        border-radius: 0.5rem;
        font-weight: bold;
    }
    .api-disconnected {
        background-color: #FEE2E2;
        color: #991B1B;
        padding: 0.5rem 1rem;
        border-radius: 0.5rem;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)


# ============================================================================
# ì„¤ì •
# ============================================================================

class Config:
    """ëŒ€ì‹œë³´ë“œ ì„¤ì •"""
    API_URL = "http://localhost:8000"
    DATA_PATH = PROJECT_ROOT / "data" / "processed"
    MODEL_PATH = PROJECT_ROOT / "models"

    # ì‹œë‚˜ë¦¬ì˜¤ í”„ë¦¬ì…‹
    SCENARIOS = {
        "normal": {"name": "í‰ë…„", "temp_delta": 0, "humidity_delta": 0, "demand_factor": 1.0},
        "heatwave_mild": {"name": "ì•½í•œ í­ì—¼ (+3Â°C)", "temp_delta": 3, "humidity_delta": -5, "demand_factor": 1.08},
        "heatwave_severe": {"name": "ì‹¬í•œ í­ì—¼ (+7Â°C)", "temp_delta": 7, "humidity_delta": -10, "demand_factor": 1.20},
        "coldwave_mild": {"name": "ì•½í•œ í•œíŒŒ (-5Â°C)", "temp_delta": -5, "humidity_delta": 5, "demand_factor": 1.10},
        "coldwave_severe": {"name": "ì‹¬í•œ í•œíŒŒ (-10Â°C)", "temp_delta": -10, "humidity_delta": 10, "demand_factor": 1.25},
    }


# ============================================================================
# API í´ë¼ì´ì–¸íŠ¸
# ============================================================================

class APIClient:
    """FastAPI ì—°ë™ í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, base_url: str = Config.API_URL):
        self.base_url = base_url
        self._health_cache = None
        self._health_time = None

    def health_check(self) -> Dict[str, Any]:
        """API ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            if response.status_code == 200:
                return response.json()
        except Exception:
            pass
        return {"status": "offline", "models_loaded": False}

    def get_models(self) -> Optional[Dict]:
        """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        try:
            response = requests.get(f"{self.base_url}/models", timeout=5)
            if response.status_code == 200:
                return response.json()
        except Exception:
            pass
        return None

    def predict(self, data: List[Dict], model_type: str = "conditional") -> Optional[Dict]:
        """ë‹¨ì¼ ì˜ˆì¸¡ API í˜¸ì¶œ"""
        try:
            response = requests.post(
                f"{self.base_url}/predict",
                json={"data": data, "model_type": model_type},
                timeout=30
            )
            if response.status_code == 200:
                return response.json()
            else:
                st.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {response.status_code} - {response.text}")
        except Exception as e:
            st.error(f"API ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

    def predict_conditional(self, data: List[Dict], mode: str = "soft") -> Optional[Dict]:
        """ì¡°ê±´ë¶€ ì˜ˆì¸¡ API í˜¸ì¶œ"""
        try:
            response = requests.post(
                f"{self.base_url}/predict/conditional",
                json={"data": data, "mode": mode},
                timeout=30
            )
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            st.error(f"ì¡°ê±´ë¶€ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return None

    def predict_batch(self, data: List[Dict], model_type: str = "demand_only", step: int = 1) -> Optional[Dict]:
        """ë°°ì¹˜ ì˜ˆì¸¡ API í˜¸ì¶œ"""
        try:
            response = requests.post(
                f"{self.base_url}/predict/batch",
                json={"data": data, "model_type": model_type, "step": step},
                timeout=60
            )
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            st.error(f"ë°°ì¹˜ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return None


# ============================================================================
# ë°ì´í„° ë¡œë”
# ============================================================================

@st.cache_data(ttl=300)
def load_historical_data() -> Optional[pd.DataFrame]:
    """ê³¼ê±° ë°ì´í„° ë¡œë“œ"""
    try:
        data_file = Config.DATA_PATH / "jeju_hourly_merged.csv"
        if data_file.exists():
            df = pd.read_csv(data_file)
            if 'datetime' in df.columns:
                df['datetime'] = pd.to_datetime(df['datetime'])
                df.set_index('datetime', inplace=True)
            return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    return None


def prepare_api_data(df: pd.DataFrame, n_points: int = 168) -> List[Dict]:
    """DataFrameì„ API ìš”ì²­ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    # ìµœê·¼ n_pointsê°œ ë°ì´í„° ì„ íƒ
    recent_data = df.tail(n_points).copy()

    api_data = []
    for idx, row in recent_data.iterrows():
        record = {
            "datetime": idx.isoformat() if isinstance(idx, pd.Timestamp) else str(idx),
            "power_demand": float(row['power_demand']),
        }

        # ê¸°ìƒ ë°ì´í„° ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if 'ê¸°ì˜¨' in row and pd.notna(row['ê¸°ì˜¨']):
            record["temperature"] = float(row['ê¸°ì˜¨'])
        if 'ìŠµë„' in row and pd.notna(row['ìŠµë„']):
            record["humidity"] = float(row['ìŠµë„'])
        if 'í’ì†' in row and pd.notna(row['í’ì†']):
            record["wind_speed"] = float(row['í’ì†'])
        if 'ê°•ìˆ˜ëŸ‰' in row and pd.notna(row['ê°•ìˆ˜ëŸ‰']):
            record["precipitation"] = float(row['ê°•ìˆ˜ëŸ‰'])

        api_data.append(record)

    return api_data


def apply_weather_modification(
    df: pd.DataFrame,
    temp_delta: float = 0,
    humidity_delta: float = 0
) -> pd.DataFrame:
    """ê¸°ìƒ ì¡°ê±´ ìˆ˜ì • ì ìš©"""
    modified = df.copy()

    if 'ê¸°ì˜¨' in modified.columns:
        modified['ê¸°ì˜¨'] = modified['ê¸°ì˜¨'] + temp_delta
    if 'ìŠµë„' in modified.columns:
        modified['ìŠµë„'] = (modified['ìŠµë„'] + humidity_delta).clip(0, 100)

    return modified


# ============================================================================
# ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸
# ============================================================================

class Charts:
    """ì°¨íŠ¸ ìƒì„± í´ë˜ìŠ¤"""

    @staticmethod
    def create_realtime_prediction_chart(
        historical_df: pd.DataFrame,
        prediction_value: float,
        prediction_time: datetime,
        model_used: str
    ) -> go.Figure:
        """ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì°¨íŠ¸"""
        fig = go.Figure()

        # ìµœê·¼ 48ì‹œê°„ ì‹¤ì œ ë°ì´í„°
        recent = historical_df.tail(48)

        fig.add_trace(go.Scatter(
            x=recent.index,
            y=recent['power_demand'],
            mode='lines',
            name='ì‹¤ì œ ìˆ˜ìš”',
            line=dict(color='#10B981', width=2)
        ))

        # ì˜ˆì¸¡ í¬ì¸íŠ¸
        fig.add_trace(go.Scatter(
            x=[prediction_time],
            y=[prediction_value],
            mode='markers+text',
            name=f'ì˜ˆì¸¡ ({model_used})',
            marker=dict(color='#EF4444', size=15, symbol='star'),
            text=[f'{prediction_value:.0f} MW'],
            textposition='top center',
            textfont=dict(size=14, color='#EF4444')
        ))

        # ì˜ˆì¸¡ì„  ì—°ê²°
        last_actual = recent['power_demand'].iloc[-1]
        last_time = recent.index[-1]

        fig.add_trace(go.Scatter(
            x=[last_time, prediction_time],
            y=[last_actual, prediction_value],
            mode='lines',
            name='ì˜ˆì¸¡ ì¶”ì´',
            line=dict(color='#3B82F6', width=2, dash='dash')
        ))

        fig.update_layout(
            title="ì‹¤ì‹œê°„ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ (API ì—°ë™)",
            xaxis_title="ì‹œê°„",
            yaxis_title="ì „ë ¥ ìˆ˜ìš” (MW)",
            height=450,
            template="plotly_white",
            legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01),
            hovermode="x unified"
        )

        return fig

    @staticmethod
    def create_batch_prediction_chart(
        predictions: List[Dict],
        historical_df: pd.DataFrame
    ) -> go.Figure:
        """ë°°ì¹˜ ì˜ˆì¸¡ ì°¨íŠ¸"""
        fig = go.Figure()

        # ìµœê·¼ ì‹¤ì œ ë°ì´í„°
        recent = historical_df.tail(72)

        fig.add_trace(go.Scatter(
            x=recent.index,
            y=recent['power_demand'],
            mode='lines',
            name='ì‹¤ì œ ìˆ˜ìš”',
            line=dict(color='#10B981', width=2)
        ))

        # ì˜ˆì¸¡ ë°ì´í„°
        pred_times = [pd.to_datetime(p['timestamp']) for p in predictions]
        pred_values = [p['prediction'] for p in predictions]

        fig.add_trace(go.Scatter(
            x=pred_times,
            y=pred_values,
            mode='lines+markers',
            name='ë°°ì¹˜ ì˜ˆì¸¡',
            line=dict(color='#3B82F6', width=2),
            marker=dict(size=6)
        ))

        fig.update_layout(
            title="ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼",
            xaxis_title="ì‹œê°„",
            yaxis_title="ì „ë ¥ ìˆ˜ìš” (MW)",
            height=400,
            template="plotly_white",
            hovermode="x unified"
        )

        return fig

    @staticmethod
    def create_scenario_comparison_chart(
        scenarios_results: Dict[str, Dict]
    ) -> go.Figure:
        """ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ ì°¨íŠ¸"""
        fig = go.Figure()

        colors = {
            'normal': '#64748B',
            'heatwave_mild': '#F97316',
            'heatwave_severe': '#DC2626',
            'coldwave_mild': '#0EA5E9',
            'coldwave_severe': '#1D4ED8'
        }

        for scenario_name, result in scenarios_results.items():
            if result and 'predictions' in result:
                config = Config.SCENARIOS.get(scenario_name, {})
                display_name = config.get('name', scenario_name)
                color = colors.get(scenario_name, '#64748B')

                pred_times = [pd.to_datetime(p['timestamp']) for p in result['predictions']]
                pred_values = [p['prediction'] for p in result['predictions']]

                fig.add_trace(go.Scatter(
                    x=pred_times,
                    y=pred_values,
                    mode='lines',
                    name=display_name,
                    line=dict(color=color, width=2)
                ))

        fig.update_layout(
            title="ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜ˆì¸¡ ë¹„êµ (API ì—°ë™)",
            xaxis_title="ì‹œê°„",
            yaxis_title="ì „ë ¥ ìˆ˜ìš” (MW)",
            height=450,
            template="plotly_white",
            legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01),
            hovermode="x unified"
        )

        return fig

    @staticmethod
    def create_model_performance_chart(model_info: Dict) -> go.Figure:
        """ëª¨ë¸ ì„±ëŠ¥ ì°¨íŠ¸"""
        models = model_info.get('models', [])

        if not models:
            return go.Figure()

        names = [m['name'] for m in models]
        features = [m.get('n_features', 0) for m in models]
        hidden_sizes = [m.get('hidden_size', 0) for m in models]

        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=("í”¼ì²˜ ìˆ˜", "Hidden Size")
        )

        fig.add_trace(
            go.Bar(x=names, y=features, marker_color='#3B82F6', name='Features'),
            row=1, col=1
        )

        fig.add_trace(
            go.Bar(x=names, y=hidden_sizes, marker_color='#10B981', name='Hidden Size'),
            row=1, col=2
        )

        fig.update_layout(height=300, showlegend=False, template="plotly_white")

        return fig

    @staticmethod
    def create_hourly_pattern_chart(data: pd.DataFrame) -> go.Figure:
        """ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ì°¨íŠ¸"""
        df = data.copy()
        df['hour'] = df.index.hour

        hourly_avg = df.groupby('hour')['power_demand'].agg(['mean', 'std']).reset_index()

        fig = go.Figure()

        fig.add_trace(go.Bar(
            x=hourly_avg['hour'],
            y=hourly_avg['mean'],
            error_y=dict(type='data', array=hourly_avg['std'], visible=True),
            marker_color='#3B82F6',
            name='í‰ê·  ìˆ˜ìš”'
        ))

        fig.update_layout(
            title="ì‹œê°„ëŒ€ë³„ í‰ê·  ì „ë ¥ ìˆ˜ìš”",
            xaxis_title="ì‹œê°„ (0-23)",
            yaxis_title="ì „ë ¥ ìˆ˜ìš” (MW)",
            height=350,
            template="plotly_white"
        )

        return fig


# ============================================================================
# ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# ============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""

    # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    api = APIClient()

    # í—¤ë”
    st.markdown('<p class="main-header">âš¡ ì œì£¼ë„ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">FastAPI ì—°ë™ | ì‹¤ì‹œê°„ ì˜ˆì¸¡ | ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„</p>', unsafe_allow_html=True)

    # API ìƒíƒœ í™•ì¸
    health = api.health_check()
    api_online = health.get("status") == "healthy"

    # ìƒë‹¨ ìƒíƒœ í‘œì‹œ
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        if api_online:
            st.markdown('<div class="api-connected">ğŸŸ¢ API ì—°ê²°ë¨</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="api-disconnected">ğŸ”´ API ì˜¤í”„ë¼ì¸</div>', unsafe_allow_html=True)

    with col2:
        st.metric("ë””ë°”ì´ìŠ¤", health.get("device", "N/A"))

    with col3:
        st.metric("ëª¨ë¸ ë¡œë“œ", "âœ…" if health.get("models_loaded") else "âŒ")

    with col4:
        uptime = health.get("uptime_seconds", 0)
        st.metric("ì—…íƒ€ì„", f"{uptime/60:.1f}ë¶„")

    st.markdown("---")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.title("âš™ï¸ ì„¤ì •")

        # ëª¨ë¸ ì„ íƒ
        st.subheader("ëª¨ë¸ ì„ íƒ")
        model_type = st.selectbox(
            "ì˜ˆì¸¡ ëª¨ë¸",
            options=["conditional", "demand_only", "weather_full"],
            index=0,
            format_func=lambda x: {
                "conditional": "ì¡°ê±´ë¶€ ì•™ìƒë¸” (ê¶Œì¥)",
                "demand_only": "ìˆ˜ìš” ì „ìš©",
                "weather_full": "ê¸°ìƒ í¬í•¨"
            }.get(x, x)
        )

        st.markdown("---")

        # ê¸°ìƒ ì¡°ê±´ ìˆ˜ì •
        st.subheader("ê¸°ìƒ ì¡°ê±´ ìˆ˜ì •")
        st.caption("ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ìš© ê¸°ìƒ ì¡°ê±´ ì¡°ì •")

        temp_delta = st.slider(
            "ì˜¨ë„ ë³€í™” (Â°C)",
            min_value=-15.0,
            max_value=15.0,
            value=0.0,
            step=0.5
        )

        humidity_delta = st.slider(
            "ìŠµë„ ë³€í™” (%)",
            min_value=-30.0,
            max_value=30.0,
            value=0.0,
            step=1.0
        )

        st.markdown("---")

        # ì‹œë‚˜ë¦¬ì˜¤ í”„ë¦¬ì…‹
        st.subheader("ì‹œë‚˜ë¦¬ì˜¤ í”„ë¦¬ì…‹")
        scenario_options = {v["name"]: k for k, v in Config.SCENARIOS.items()}
        selected_preset = st.selectbox(
            "í”„ë¦¬ì…‹ ì„ íƒ",
            options=["ì§ì ‘ ì„¤ì •"] + list(scenario_options.keys())
        )

        if selected_preset != "ì§ì ‘ ì„¤ì •":
            preset_key = scenario_options[selected_preset]
            preset = Config.SCENARIOS[preset_key]
            temp_delta = float(preset["temp_delta"])
            humidity_delta = float(preset["humidity_delta"])
            st.info(f"ì˜¨ë„: {temp_delta:+.0f}Â°C, ìŠµë„: {humidity_delta:+.0f}%")

        st.markdown("---")

        # ë°ì´í„° ë²”ìœ„
        st.subheader("ë°ì´í„° ë²”ìœ„")
        date_range = st.date_input(
            "ê¸°ê°„ ì„ íƒ",
            value=(
                datetime.now().date() - timedelta(days=7),
                datetime.now().date()
            )
        )

        st.markdown("---")
        st.caption(f"API: {Config.API_URL}")

    # ë°ì´í„° ë¡œë“œ
    historical_data = load_historical_data()

    if historical_data is None or len(historical_data) == 0:
        st.error("ê³¼ê±° ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.success(f"ë°ì´í„° ë¡œë“œ: {len(historical_data):,}ê°œ ë ˆì½”ë“œ (2013-2024)")

    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ”® ì‹¤ì‹œê°„ ì˜ˆì¸¡",
        "ğŸŒ¡ï¸ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„",
        "ğŸ“Š ê³¼ê±° ë°ì´í„°",
        "ğŸ¤– ëª¨ë¸ ì •ë³´",
        "â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´"
    ])

    # ==========================================================================
    # íƒ­ 1: ì‹¤ì‹œê°„ ì˜ˆì¸¡
    # ==========================================================================
    with tab1:
        st.header("ì‹¤ì‹œê°„ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡")

        if not api_online:
            st.warning("API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. APIë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            st.code("uvicorn api.main:app --host 0.0.0.0 --port 8000")
        else:
            col1, col2 = st.columns([3, 1])

            with col2:
                st.subheader("ì˜ˆì¸¡ ì‹¤í–‰")

                if st.button("ğŸš€ ì˜ˆì¸¡ ì‹¤í–‰", type="primary", use_container_width=True):
                    with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
                        # ê¸°ìƒ ì¡°ê±´ ìˆ˜ì • ì ìš©
                        modified_data = apply_weather_modification(
                            historical_data,
                            temp_delta=temp_delta,
                            humidity_delta=humidity_delta
                        )

                        # API ë°ì´í„° ì¤€ë¹„
                        api_data = prepare_api_data(modified_data, n_points=168)

                        # API í˜¸ì¶œ
                        if model_type == "conditional":
                            result = api.predict_conditional(api_data, mode="soft")
                        else:
                            result = api.predict(api_data, model_type=model_type)

                        if result:
                            st.session_state['last_prediction'] = result
                            st.success("ì˜ˆì¸¡ ì™„ë£Œ!")

                # ê²°ê³¼ í‘œì‹œ
                if 'last_prediction' in st.session_state:
                    result = st.session_state['last_prediction']

                    st.markdown("---")
                    st.subheader("ì˜ˆì¸¡ ê²°ê³¼")

                    st.metric(
                        "ì˜ˆì¸¡ ìˆ˜ìš”",
                        f"{result['prediction']:.1f} MW",
                        delta=f"{result['prediction'] - historical_data['power_demand'].iloc[-1]:.1f} MW"
                    )

                    st.caption(f"ëª¨ë¸: {result.get('model_used', 'N/A')}")
                    st.caption(f"ì²˜ë¦¬ì‹œê°„: {result.get('processing_time_ms', 0):.1f}ms")

                    if 'context' in result:
                        with st.expander("ìƒì„¸ ì»¨í…ìŠ¤íŠ¸"):
                            st.json(result['context'])

            with col1:
                if 'last_prediction' in st.session_state:
                    result = st.session_state['last_prediction']

                    pred_time = pd.to_datetime(result.get('timestamp', datetime.now()))

                    fig = Charts.create_realtime_prediction_chart(
                        historical_data,
                        result['prediction'],
                        pred_time,
                        result.get('model_used', 'unknown')
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("ì˜¤ë¥¸ìª½ì˜ 'ì˜ˆì¸¡ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì˜ˆì¸¡ì„ ì‹œì‘í•˜ì„¸ìš”.")

                    # ê¸°ë³¸ ì°¨íŠ¸ í‘œì‹œ
                    recent = historical_data.tail(72)
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=recent.index,
                        y=recent['power_demand'],
                        mode='lines',
                        name='ìµœê·¼ ìˆ˜ìš”',
                        line=dict(color='#10B981', width=2)
                    ))
                    fig.update_layout(
                        title="ìµœê·¼ 72ì‹œê°„ ì „ë ¥ ìˆ˜ìš”",
                        xaxis_title="ì‹œê°„",
                        yaxis_title="ì „ë ¥ ìˆ˜ìš” (MW)",
                        height=400,
                        template="plotly_white"
                    )
                    st.plotly_chart(fig, use_container_width=True)

    # ==========================================================================
    # íƒ­ 2: ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
    # ==========================================================================
    with tab2:
        st.header("ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ (What-If)")

        if not api_online:
            st.warning("API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.markdown("""
            ë‹¤ì–‘í•œ ê¸°ìƒ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ì „ë ¥ ìˆ˜ìš”ë¥¼ APIë¥¼ í†µí•´ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
            """)

            col1, col2 = st.columns(2)

            with col1:
                compare_scenarios = st.multiselect(
                    "ë¹„êµí•  ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ",
                    options=list(Config.SCENARIOS.keys()),
                    default=["normal", "heatwave_mild", "coldwave_mild"],
                    format_func=lambda x: Config.SCENARIOS[x]["name"]
                )

            with col2:
                batch_step = st.slider("ì˜ˆì¸¡ ê°„ê²© (ì‹œê°„)", 1, 6, 1)

            if st.button("ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì‹¤í–‰", type="primary"):
                if compare_scenarios:
                    with st.spinner("ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì¤‘..."):
                        scenarios_results = {}

                        progress_bar = st.progress(0)

                        for i, scenario in enumerate(compare_scenarios):
                            config = Config.SCENARIOS[scenario]

                            # ê¸°ìƒ ì¡°ê±´ ìˆ˜ì •
                            modified_data = apply_weather_modification(
                                historical_data,
                                temp_delta=config["temp_delta"],
                                humidity_delta=config["humidity_delta"]
                            )

                            # API ë°ì´í„° ì¤€ë¹„
                            api_data = prepare_api_data(modified_data, n_points=200)

                            # ë°°ì¹˜ ì˜ˆì¸¡
                            result = api.predict_batch(api_data, model_type="demand_only", step=batch_step)

                            if result:
                                # ìˆ˜ìš” ê³„ìˆ˜ ì ìš©
                                for pred in result['predictions']:
                                    pred['prediction'] *= config["demand_factor"]

                                scenarios_results[scenario] = result

                            progress_bar.progress((i + 1) / len(compare_scenarios))

                        st.session_state['scenarios_results'] = scenarios_results
                        st.success("ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì™„ë£Œ!")

            # ê²°ê³¼ í‘œì‹œ
            if 'scenarios_results' in st.session_state:
                results = st.session_state['scenarios_results']

                if results:
                    # ë¹„êµ ì°¨íŠ¸
                    fig = Charts.create_scenario_comparison_chart(results)
                    st.plotly_chart(fig, use_container_width=True)

                    # í†µê³„ í…Œì´ë¸”
                    st.subheader("ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ í†µê³„")

                    comparison_data = []
                    for scenario_name, result in results.items():
                        if result and 'predictions' in result:
                            config = Config.SCENARIOS[scenario_name]
                            predictions = [p['prediction'] for p in result['predictions']]

                            comparison_data.append({
                                "ì‹œë‚˜ë¦¬ì˜¤": config["name"],
                                "ì˜¨ë„ ë³€í™”": f"{config['temp_delta']:+d}Â°C",
                                "ìŠµë„ ë³€í™”": f"{config['humidity_delta']:+d}%",
                                "í‰ê·  ìˆ˜ìš”": f"{np.mean(predictions):.1f} MW",
                                "í”¼í¬ ìˆ˜ìš”": f"{np.max(predictions):.1f} MW",
                                "ìµœì†Œ ìˆ˜ìš”": f"{np.min(predictions):.1f} MW",
                            })

                    if comparison_data:
                        st.dataframe(
                            pd.DataFrame(comparison_data),
                            use_container_width=True,
                            hide_index=True
                        )

    # ==========================================================================
    # íƒ­ 3: ê³¼ê±° ë°ì´í„°
    # ==========================================================================
    with tab3:
        st.header("ê³¼ê±° ë°ì´í„° ë¶„ì„")

        # ë‚ ì§œ í•„í„°ë§
        if isinstance(date_range, tuple) and len(date_range) == 2:
            start_date, end_date = date_range
            mask = (historical_data.index.date >= start_date) & (historical_data.index.date <= end_date)
            filtered_data = historical_data[mask]
        else:
            filtered_data = historical_data.tail(168)

        if len(filtered_data) > 0:
            st.success(f"ì„ íƒ ê¸°ê°„: {len(filtered_data):,}ê°œ ë ˆì½”ë“œ")

            # í†µê³„
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("í‰ê·  ìˆ˜ìš”", f"{filtered_data['power_demand'].mean():.1f} MW")
            with col2:
                st.metric("ìµœëŒ€ ìˆ˜ìš”", f"{filtered_data['power_demand'].max():.1f} MW")
            with col3:
                st.metric("ìµœì†Œ ìˆ˜ìš”", f"{filtered_data['power_demand'].min():.1f} MW")
            with col4:
                st.metric("í‘œì¤€í¸ì°¨", f"{filtered_data['power_demand'].std():.1f} MW")

            # ì°¨íŠ¸
            col1, col2 = st.columns(2)

            with col1:
                # ì‹œê³„ì—´ ì°¨íŠ¸
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=filtered_data.index,
                    y=filtered_data['power_demand'],
                    mode='lines',
                    name='ì „ë ¥ ìˆ˜ìš”',
                    line=dict(color='#3B82F6')
                ))
                fig.update_layout(
                    title="ì „ë ¥ ìˆ˜ìš” ì¶”ì´",
                    xaxis_title="ì‹œê°„",
                    yaxis_title="MW",
                    height=400,
                    template="plotly_white"
                )
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                # ì‹œê°„ëŒ€ë³„ íŒ¨í„´
                fig = Charts.create_hourly_pattern_chart(filtered_data)
                st.plotly_chart(fig, use_container_width=True)

            # ìƒì„¸ ë°ì´í„°
            with st.expander("ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
                st.dataframe(
                    filtered_data[['power_demand', 'ê¸°ì˜¨', 'ìŠµë„', 'í’ì†']].round(2),
                    use_container_width=True
                )
        else:
            st.warning("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ==========================================================================
    # íƒ­ 4: ëª¨ë¸ ì •ë³´
    # ==========================================================================
    with tab4:
        st.header("ëª¨ë¸ ì •ë³´")

        if api_online:
            model_info = api.get_models()

            if model_info:
                # ëª¨ë¸ ëª©ë¡
                st.subheader("ë¡œë“œëœ ëª¨ë¸")

                for model in model_info.get('models', []):
                    with st.container():
                        col1, col2, col3 = st.columns(3)

                        with col1:
                            st.markdown(f"### {model['name']}")
                            st.caption(f"íƒ€ì…: {model['type'].upper()}")

                        with col2:
                            st.metric("í”¼ì²˜ ìˆ˜", model.get('n_features', 'N/A'))
                            st.metric("ì‹œí€€ìŠ¤ ê¸¸ì´", model.get('seq_length', 'N/A'))

                        with col3:
                            st.metric("Hidden Size", model.get('hidden_size', 'N/A'))
                            st.metric("ë ˆì´ì–´ ìˆ˜", model.get('num_layers', 'N/A'))

                        st.markdown("---")

                # ëª¨ë¸ ë¹„êµ ì°¨íŠ¸
                fig = Charts.create_model_performance_chart(model_info)
                st.plotly_chart(fig, use_container_width=True)

                st.info(f"ê¸°ë³¸ ëª¨ë¸: **{model_info.get('default_model', 'conditional')}**")
        else:
            st.warning("APIì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ==========================================================================
    # íƒ­ 5: ì‹œìŠ¤í…œ ì •ë³´
    # ==========================================================================
    with tab5:
        st.header("ì‹œìŠ¤í…œ ì •ë³´")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("API ì„œë²„")

            st.json(health)

            if st.button("ìƒˆë¡œê³ ì¹¨"):
                st.rerun()

        with col2:
            st.subheader("ë°ì´í„° ì •ë³´")

            if historical_data is not None:
                st.markdown(f"""
                - **ì´ ë ˆì½”ë“œ**: {len(historical_data):,}
                - **ê¸°ê°„**: {historical_data.index.min()} ~ {historical_data.index.max()}
                - **ì»¬ëŸ¼ ìˆ˜**: {len(historical_data.columns)}
                - **ìˆ˜ìš” ë²”ìœ„**: {historical_data['power_demand'].min():.1f} ~ {historical_data['power_demand'].max():.1f} MW
                """)

        # API ì—”ë“œí¬ì¸íŠ¸
        st.subheader("API ì—”ë“œí¬ì¸íŠ¸")

        endpoints = [
            {"Method": "GET", "Endpoint": "/health", "ì„¤ëª…": "ìƒíƒœ í™•ì¸"},
            {"Method": "GET", "Endpoint": "/models", "ì„¤ëª…": "ëª¨ë¸ ì •ë³´"},
            {"Method": "POST", "Endpoint": "/predict", "ì„¤ëª…": "ë‹¨ì¼ ì˜ˆì¸¡"},
            {"Method": "POST", "Endpoint": "/predict/conditional", "ì„¤ëª…": "ì¡°ê±´ë¶€ ì˜ˆì¸¡"},
            {"Method": "POST", "Endpoint": "/predict/batch", "ì„¤ëª…": "ë°°ì¹˜ ì˜ˆì¸¡"},
        ]

        st.dataframe(pd.DataFrame(endpoints), use_container_width=True, hide_index=True)

        # ì‚¬ìš© ê°€ì´ë“œ
        with st.expander("API ì‚¬ìš© ì˜ˆì‹œ"):
            st.code("""
import requests

# 1. ìƒíƒœ í™•ì¸
health = requests.get("http://localhost:8000/health").json()
print(f"Status: {health['status']}")

# 2. ì¡°ê±´ë¶€ ì˜ˆì¸¡
response = requests.post(
    "http://localhost:8000/predict/conditional",
    json={
        "data": [...],  # 168ê°œ ì´ìƒì˜ ì‹œê³„ì—´ ë°ì´í„°
        "mode": "soft"
    }
)
result = response.json()
print(f"ì˜ˆì¸¡: {result['prediction']} MW")
print(f"ëª¨ë¸: {result['model_used']}")
            """, language="python")


# ============================================================================
# ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    main()
