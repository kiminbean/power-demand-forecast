"""
Train/Test Data Distribution Analysis
=====================================
ì „ë ¥ ìˆ˜ìš” ë°ì´í„°ì˜ Train/Test ë¶„í¬ ì°¨ì´ ë¶„ì„

ëª©ì : RÂ² ìŒìˆ˜ ì›ì¸ ë¶„ì„ (Scaling ë²”ìœ„ ì´íƒˆ ì—¬ë¶€ í™•ì¸)

Author: Hybrid Agent Pipeline (Claude + Gemini)
Date: 2024-12
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

# í”„ë¡œì íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.parent
DATA_PATH = PROJECT_ROOT / 'data' / 'processed' / 'jeju_daily_dataset.csv'
OUTPUT_DIR = PROJECT_ROOT / 'results' / 'analysis'
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# ë¶„í•  ë¹„ìœ¨ (í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼)
TRAIN_RATIO = 0.8
VAL_RATIO = 0.1
SEQUENCE_LENGTH = 14


def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    df = pd.read_csv(DATA_PATH, parse_dates=['date'])
    df = df.sort_values('date').reset_index(drop=True)
    return df


def split_data(df: pd.DataFrame) -> tuple:
    """Train/Val/Test ë¶„í•  (ì‹œí€€ìŠ¤ ê³ ë ¤)"""
    n = len(df) - SEQUENCE_LENGTH
    train_end = int(n * TRAIN_RATIO) + SEQUENCE_LENGTH
    val_end = int(n * (TRAIN_RATIO + VAL_RATIO)) + SEQUENCE_LENGTH
    
    train_df = df.iloc[:train_end]
    val_df = df.iloc[train_end:val_end]
    test_df = df.iloc[val_end:]
    
    return train_df, val_df, test_df


def compute_statistics(df: pd.DataFrame, name: str) -> dict:
    """ê¸°ìˆ  í†µê³„ëŸ‰ ê³„ì‚°"""
    power = df['power_sum']
    stats = {
        'name': name,
        'count': len(power),
        'mean': power.mean(),
        'std': power.std(),
        'min': power.min(),
        'max': power.max(),
        'median': power.median(),
        'date_start': df['date'].min(),
        'date_end': df['date'].max(),
    }
    return stats


def plot_timeseries(df: pd.DataFrame, train_df: pd.DataFrame, val_df: pd.DataFrame, test_df: pd.DataFrame):
    """ì „ì²´ ì‹œê³„ì—´ + Train/Test êµ¬ê°„ í‘œì‹œ"""
    fig, ax = plt.subplots(figsize=(14, 6))
    
    # ì „ì²´ ì‹œê³„ì—´
    ax.plot(df['date'], df['power_sum'], color='gray', alpha=0.3, linewidth=0.5, label='All Data')
    
    # Train/Val/Test êµ¬ê°„
    ax.plot(train_df['date'], train_df['power_sum'], color='blue', alpha=0.7, linewidth=0.8, label=f'Train ({len(train_df):,})')
    ax.plot(val_df['date'], val_df['power_sum'], color='green', alpha=0.7, linewidth=0.8, label=f'Validation ({len(val_df):,})')
    ax.plot(test_df['date'], test_df['power_sum'], color='red', alpha=0.7, linewidth=0.8, label=f'Test ({len(test_df):,})')
    
    # Train Max ë¼ì¸
    train_max = train_df['power_sum'].max()
    ax.axhline(y=train_max, color='blue', linestyle='--', alpha=0.5, label=f'Train Max: {train_max:,.0f}')
    
    ax.set_xlabel('Date')
    ax.set_ylabel('Power Demand (MW)')
    ax.set_title('Jeju Power Demand: Train/Val/Test Split Analysis')
    ax.legend(loc='upper left')
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'timeseries_split.png', dpi=150)
    print(f"âœ… Saved: {OUTPUT_DIR / 'timeseries_split.png'}")
    plt.close()


def plot_distribution(train_df: pd.DataFrame, test_df: pd.DataFrame):
    """Train vs Test ë¶„í¬ ë¹„êµ íˆìŠ¤í† ê·¸ë¨"""
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # íˆìŠ¤í† ê·¸ë¨
    ax1 = axes[0]
    ax1.hist(train_df['power_sum'], bins=50, alpha=0.7, color='blue', label='Train', density=True)
    ax1.hist(test_df['power_sum'], bins=50, alpha=0.7, color='red', label='Test', density=True)
    ax1.axvline(train_df['power_sum'].max(), color='blue', linestyle='--', label=f'Train Max: {train_df["power_sum"].max():,.0f}')
    ax1.axvline(test_df['power_sum'].max(), color='red', linestyle='--', label=f'Test Max: {test_df["power_sum"].max():,.0f}')
    ax1.set_xlabel('Power Demand (MW)')
    ax1.set_ylabel('Density')
    ax1.set_title('Distribution Comparison')
    ax1.legend()
    
    # Box plot
    ax2 = axes[1]
    ax2.boxplot([train_df['power_sum'], test_df['power_sum']], labels=['Train', 'Test'])
    ax2.set_ylabel('Power Demand (MW)')
    ax2.set_title('Box Plot Comparison')
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'distribution_comparison.png', dpi=150)
    print(f"âœ… Saved: {OUTPUT_DIR / 'distribution_comparison.png'}")
    plt.close()


def plot_yearly_trend(df: pd.DataFrame):
    """ì—°ë„ë³„ í‰ê·  ì „ë ¥ ìˆ˜ìš” ì¶”ì„¸"""
    yearly = df.groupby(df['date'].dt.year)['power_sum'].agg(['mean', 'max', 'min']).reset_index()
    yearly.columns = ['year', 'mean', 'max', 'min']
    
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(yearly['year'], yearly['mean'], marker='o', linewidth=2, label='Mean')
    ax.fill_between(yearly['year'], yearly['min'], yearly['max'], alpha=0.2, label='Min-Max Range')
    
    # Train/Test êµ¬ë¶„ì„ 
    ax.axvline(x=2022.5, color='red', linestyle='--', alpha=0.7, label='Train/Test Split')
    
    ax.set_xlabel('Year')
    ax.set_ylabel('Power Demand (MW)')
    ax.set_title('Yearly Power Demand Trend')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'yearly_trend.png', dpi=150)
    print(f"âœ… Saved: {OUTPUT_DIR / 'yearly_trend.png'}")
    plt.close()


def main():
    print("="*60)
    print("ğŸ“Š ANALYSIS-001: Train/Test Distribution Analysis")
    print("="*60)
    
    # ë°ì´í„° ë¡œë“œ
    df = load_data()
    print(f"\nğŸ“‚ Loaded {len(df):,} records")
    print(f"   Date range: {df['date'].min()} ~ {df['date'].max()}")
    
    # ë°ì´í„° ë¶„í• 
    train_df, val_df, test_df = split_data(df)
    
    # ê¸°ìˆ  í†µê³„ëŸ‰ ê³„ì‚°
    train_stats = compute_statistics(train_df, 'Train')
    val_stats = compute_statistics(val_df, 'Validation')
    test_stats = compute_statistics(test_df, 'Test')
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“‹ STATISTICS COMPARISON")
    print("="*60)
    
    print(f"\n{'Metric':<15} {'Train':>15} {'Validation':>15} {'Test':>15}")
    print("-" * 60)
    print(f"{'Count':<15} {train_stats['count']:>15,} {val_stats['count']:>15,} {test_stats['count']:>15,}")
    print(f"{'Mean':<15} {train_stats['mean']:>15,.1f} {val_stats['mean']:>15,.1f} {test_stats['mean']:>15,.1f}")
    print(f"{'Std':<15} {train_stats['std']:>15,.1f} {val_stats['std']:>15,.1f} {test_stats['std']:>15,.1f}")
    print(f"{'Min':<15} {train_stats['min']:>15,.1f} {val_stats['min']:>15,.1f} {test_stats['min']:>15,.1f}")
    print(f"{'Max':<15} {train_stats['max']:>15,.1f} {val_stats['max']:>15,.1f} {test_stats['max']:>15,.1f}")
    print(f"{'Median':<15} {train_stats['median']:>15,.1f} {val_stats['median']:>15,.1f} {test_stats['median']:>15,.1f}")
    print("-" * 60)
    print(f"{'Date Start':<15} {str(train_stats['date_start'].date()):>15} {str(val_stats['date_start'].date()):>15} {str(test_stats['date_start'].date()):>15}")
    print(f"{'Date End':<15} {str(train_stats['date_end'].date()):>15} {str(val_stats['date_end'].date()):>15} {str(test_stats['date_end'].date()):>15}")
    
    # ìŠ¤ì¼€ì¼ë§ ì´íƒˆ ë¶„ì„
    print("\n" + "="*60)
    print("âš ï¸ SCALING RANGE ANALYSIS")
    print("="*60)
    
    train_max = train_stats['max']
    test_max = test_stats['max']
    test_over_train = (test_df['power_sum'] > train_max).sum()
    test_over_ratio = test_over_train / len(test_df) * 100
    
    print(f"\n   Train Max: {train_max:,.1f} MW")
    print(f"   Test Max:  {test_max:,.1f} MW")
    print(f"   Test > Train Max: {test_over_train:,} records ({test_over_ratio:.1f}%)")
    
    if test_max > train_max:
        overflow = ((test_max - train_max) / train_max) * 100
        print(f"\n   âš ï¸ SCALING OVERFLOW DETECTED!")
        print(f"   Test Max exceeds Train Max by {overflow:.1f}%")
        print(f"   â†’ MinMaxScaler will produce values > 1.0 for Test data")
        print(f"   â†’ LSTM cannot extrapolate beyond training range!")
    else:
        print(f"\n   âœ… No scaling overflow detected")
    
    # ì‹œê°í™”
    print("\nğŸ“ˆ Generating visualizations...")
    plot_timeseries(df, train_df, val_df, test_df)
    plot_distribution(train_df, test_df)
    plot_yearly_trend(df)
    
    # ê²°ë¡ 
    print("\n" + "="*60)
    print("ğŸ“ CONCLUSION")
    print("="*60)
    
    mean_increase = ((test_stats['mean'] - train_stats['mean']) / train_stats['mean']) * 100
    print(f"\n   Mean increase (Trainâ†’Test): {mean_increase:+.1f}%")
    
    if mean_increase > 10:
        print(f"\n   ğŸ”´ CRITICAL: Significant distribution shift detected!")
        print(f"   Recommendation: Apply differencing or use expanding window validation")
    elif mean_increase > 5:
        print(f"\n   ğŸŸ¡ WARNING: Moderate distribution shift detected")
        print(f"   Recommendation: Consider TimeSeriesSplit cross-validation")
    else:
        print(f"\n   ğŸŸ¢ Distribution shift is within acceptable range")
    
    print(f"\n   Output directory: {OUTPUT_DIR}")


if __name__ == "__main__":
    main()
